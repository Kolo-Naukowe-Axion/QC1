{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXjsA2rXJYoLRt9Aj74/eA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kolo-Naukowe-Axion/QC1/blob/dnn/dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcXZafusqqK2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "gM7Icsn7V4a9",
        "outputId": "24521a8b-9ef1-4958-83c6-1e36cbaa2a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking data, conversion to numpy"
      ],
      "metadata": {
        "id": "zW-SX5adq2Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "banknote_authentication = fetch_ucirepo(id=267)\n",
        "\n",
        "X_raw = banknote_authentication.data.features\n",
        "y_raw = banknote_authentication.data.targets\n",
        "\n",
        "X = X_raw.values\n",
        "y = y_raw.values.ravel()"
      ],
      "metadata": {
        "id": "vNmCRe1Cq_Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test and train split"
      ],
      "metadata": {
        "id": "0UFJ8FkrrkIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# stadarization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "print(f\"Training Tensor Shape: {X_train_tensor.shape}\")\n",
        "print(f\"Testing Tensor Shape: {X_test_tensor.shape}\")"
      ],
      "metadata": {
        "id": "vEkkupNXrmq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85ecbea-be44-48aa-d067-a58576c3241a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Tensor Shape: torch.Size([1097, 4])\n",
            "Testing Tensor Shape: torch.Size([275, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BanknoteDNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BanknoteDNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(4, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.layer3 = nn.Linear(32, 16)\n",
        "        self.output = nn.Linear(16, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.sigmoid(self.output(x))\n",
        "        return x\n",
        "\n",
        "model = BanknoteDNN().to(device)"
      ],
      "metadata": {
        "id": "KqCrWK8EseAb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 200\n",
        "print(\"\\nStarting training...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    outputs = model(X_train_tensor)\n",
        "\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = criterion(test_outputs, y_test_tensor)\n",
        "        predicted = (test_outputs > 0.5).float()\n",
        "        correct = (predicted == y_test_tensor).float().sum()\n",
        "        accuracy = correct / y_test_tensor.shape[0]\n",
        "\n",
        "    if epoch%10==0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {loss.item():.4f} | Test Loss: {test_loss.item():.4f} | Test Acc: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7wh4QxGstoz",
        "outputId": "24894e3e-9007-46c2-f7da-8bf19381322b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "Epoch 1/200 | Train Loss: 0.7086 | Test Loss: 0.7007 | Test Acc: 0.4618\n",
            "Epoch 11/200 | Train Loss: 0.6720 | Test Loss: 0.6657 | Test Acc: 0.4909\n",
            "Epoch 21/200 | Train Loss: 0.6266 | Test Loss: 0.6202 | Test Acc: 0.8073\n",
            "Epoch 31/200 | Train Loss: 0.5652 | Test Loss: 0.5598 | Test Acc: 0.8727\n",
            "Epoch 41/200 | Train Loss: 0.4764 | Test Loss: 0.4716 | Test Acc: 0.8873\n",
            "Epoch 51/200 | Train Loss: 0.3591 | Test Loss: 0.3571 | Test Acc: 0.9200\n",
            "Epoch 61/200 | Train Loss: 0.2419 | Test Loss: 0.2412 | Test Acc: 0.9382\n",
            "Epoch 71/200 | Train Loss: 0.1511 | Test Loss: 0.1494 | Test Acc: 0.9600\n",
            "Epoch 81/200 | Train Loss: 0.0982 | Test Loss: 0.0913 | Test Acc: 0.9855\n",
            "Epoch 91/200 | Train Loss: 0.0662 | Test Loss: 0.0595 | Test Acc: 0.9855\n",
            "Epoch 101/200 | Train Loss: 0.0560 | Test Loss: 0.0415 | Test Acc: 0.9855\n",
            "Epoch 111/200 | Train Loss: 0.0431 | Test Loss: 0.0313 | Test Acc: 0.9964\n",
            "Epoch 121/200 | Train Loss: 0.0329 | Test Loss: 0.0242 | Test Acc: 1.0000\n",
            "Epoch 131/200 | Train Loss: 0.0301 | Test Loss: 0.0194 | Test Acc: 1.0000\n",
            "Epoch 141/200 | Train Loss: 0.0273 | Test Loss: 0.0153 | Test Acc: 1.0000\n",
            "Epoch 151/200 | Train Loss: 0.0224 | Test Loss: 0.0123 | Test Acc: 1.0000\n",
            "Epoch 161/200 | Train Loss: 0.0180 | Test Loss: 0.0101 | Test Acc: 1.0000\n",
            "Epoch 171/200 | Train Loss: 0.0161 | Test Loss: 0.0084 | Test Acc: 1.0000\n",
            "Epoch 181/200 | Train Loss: 0.0135 | Test Loss: 0.0071 | Test Acc: 1.0000\n",
            "Epoch 191/200 | Train Loss: 0.0148 | Test Loss: 0.0059 | Test Acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "preds = clf.predict(X_test)\n",
        "print(f\"Simple model accuracy: {accuracy_score(y_test, preds)*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9D9CkQPN3ee",
        "outputId": "bd55b6d5-2b75-4019-ecf2-97bc6aed6efc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple model accuracy: 97.82%\n"
          ]
        }
      ]
    }
  ]
}