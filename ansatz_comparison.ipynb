{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kolo-Naukowe-Axion/QC1/blob/main/ansatz_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLzI6vhj-pd"
      },
      "source": [
        "\n",
        "\n",
        "##Quantum Classifier - ansatz comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install qiskit qiskit_machine_learning\n",
        "%pip install ucimlrepo\n",
        "%pip install torch\n",
        "%pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qy5f6-Mjv3in",
        "outputId": "a0a787bb-ab86-4f92-d6ad-60c90a1bfe9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.3.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Downloading qiskit-2.3.0-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_machine_learning-0.9.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit, qiskit_machine_learning\n",
            "Successfully installed qiskit-2.3.0 qiskit_machine_learning-0.9.0 rustworkx-0.17.1 stevedore-5.6.0\n",
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LKSJGRyG0ouM"
      },
      "outputs": [],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "import sys          # Standard library module for system-specific parameters and functions\n",
        "import subprocess   # Standard library module for spawning new processes\n",
        "from sklearn.preprocessing import MinMaxScaler # Importuje MinMaxScaler do skalowania danych\n",
        "from sklearn.model_selection import train_test_split # Importuje train_test_split do podziaÅ‚u danych\n",
        "from ucimlrepo import fetch_ucirepo     # Importuje fetch_ucirepo do pobierania zestawÃ³w danych z UCI ML Repository\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n",
        "import sys\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ucimlrepo import fetch_ucirepo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "enUz4SJl6Fnh"
      },
      "outputs": [],
      "source": [
        "def ensure_package(pkg_name, import_name=None):\n",
        "    import_name = import_name or pkg_name\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
        "\n",
        "# Ensure all requirements are met\n",
        "ensure_package('numpy')\n",
        "ensure_package('scikit-learn', 'sklearn')\n",
        "ensure_package('ucimlrepo')\n",
        "ensure_package('qiskit')\n",
        "\n",
        "def prepare_data():\n",
        "    \"\"\"\n",
        "    Fetches the banknote authentication dataset and returns scaled train/test splits.\n",
        "    Features are scaled to [0, pi] specifically for Angle Encoding.\n",
        "    \"\"\"\n",
        "    banknote_authentication = fetch_ucirepo(id=267)\n",
        "    X = banknote_authentication.data.features.to_numpy()\n",
        "    y = banknote_authentication.data.targets.to_numpy().ravel()\n",
        "\n",
        "    variance = X[:, 0].reshape(-1, 1)\n",
        "    skewness = X[:, 1].reshape(-1, 1)\n",
        "\n",
        "    interaction = skewness * variance\n",
        "    X_expanded = np.hstack((X, interaction))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_expanded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "\n",
        "# Global availability of data\n",
        "X_tr, X_te, y_tr, y_te = prepare_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸ”¬ Ansatz 1: Global Ring Entangler (Simulation-Optimized)"
      ],
      "metadata": {
        "id": "XVh14trAwFyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##**Overview**\n",
        "\n",
        "This ansatz is designed to maximize expressibility and entanglement capability by leveraging a global connectivity pattern. It follows a \"Circuit-centric\" design philosophy, prioritizing high-dimensional state representation to achieve superior classification performance in ideal environments.\n",
        "\n",
        "##**Technical Architecture**\n",
        "\n",
        " * **Layered Structure:** The circuit employs a dual-layer strategy consisting of\n",
        "independent rotation sub-layers ($RY$, $RX$) and sophisticated entanglement blocks.\n",
        " * **Ring Topology:** Entanglement is implemented via a circular chain where each qubit $i$ is coupled with qubit $(i+1) \\pmod n$. This ensures that information from any qubit can reach any other qubit in the shortest possible path.\n",
        " * **Parametric Controlled Rotations:** Unlike standard CNOT-based circuits, this model utilizes CRX and CRY gates. These allow the model to learn not just whether to entangle, but the intensity of the entanglement, leading to high-precision decision boundaries.\n",
        " * **Reverse-Flow Correlation:** The second sub-layer reverses the entanglement direction ($i \\to i-1$), facilitating a rapid diffusion of features across the entire register.\n",
        " * **Performance & Benchmarks:**\n",
        "    In noise-free simulations, this architecture demonstrates exceptional learning capabilities:\n",
        "      * **Accuracy:** consistently achieves **>90%** on binary classification tasks.\n",
        "      * **Flexibility:** High parameter density allows for complex non-linear mapping of input data.\n",
        "  \n",
        "##**Scientific Reference**\n",
        "\n",
        "  The implementation of this ansatz is based on the architectural principles discussed in: [Quantum Machine Learning in Liquid â€“ HavlÃ­Äek et al. (2019) arXiv:1905.10876](https://https://arxiv.org/abs/1905.10876)\n",
        "  \n",
        "##**The \"Hardware Gap\" (Motivation for Ansatz 2)**\n",
        "While mathematically superior, Ansatz 1 poses significant challenges for physical quantum processors like the Odra system:\n",
        "* **Connectivity Constraints:** Real hardware rarely supports a physical \"Ring.\" Connecting the first and last qubits requires multiple SWAP gates, which significantly increase circuit depth and decoherence.\n",
        "* **Gate Decomposition:** $CRX$ and $CRY$ are not native gates. On hardware, they are decomposed into multiple CNOTs and single-qubit rotations, multiplying the error rate for every single operation."
      ],
      "metadata": {
        "id": "BXTxoldF8967"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pz4kqrFfANdX"
      },
      "outputs": [],
      "source": [
        "def ansatz(n_qubits, depth):\n",
        "    \"\"\"\n",
        "    The code below constructs the ansatz. It is built using the Qiskit library\n",
        "    and utilizes its built-in tools, such as ParameterVector, to easily iterate\n",
        "    over rotation gate parameters.\n",
        "\n",
        "    The implementation assumes an even number of layers (depth). Each layer consists\n",
        "    of a sub-layer of independent gates and a sub-layer of entanglement.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a vector of learnable parameters.\n",
        "    # Total parameters = 2 * num_qubits * depth (2 * n_qubits per full loop iteration).\n",
        "    theta = ParameterVector('Î¸', 2 * n_qubits * depth)\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    param_idx = 0\n",
        "\n",
        "    # The loop iterates (depth // 2) times.\n",
        "    for j in range(depth // 2):\n",
        "\n",
        "        # -------- Layer 1 --------\n",
        "\n",
        "        # Sub-layer: Independent RY rotations\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(theta[param_idx], i)\n",
        "            param_idx += 1\n",
        "\n",
        "        # Sub-layer: Entanglement (CRX) - Ring Topology\n",
        "        # Connects i -> i+1 (wrapping around to 0 at the end)\n",
        "        for i in range(n_qubits):\n",
        "            control = i\n",
        "            target = (i + 1) % n_qubits\n",
        "            qc.crx(theta[param_idx], control, target)\n",
        "            param_idx += 1\n",
        "\n",
        "\n",
        "        # -------- Layer 2 --------\n",
        "\n",
        "        # Sub-layer: Independent RX rotations\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(theta[param_idx], i)\n",
        "            param_idx += 1\n",
        "\n",
        "        # Sub-layer: Entanglement (CRY) - Reverse Ring Topology\n",
        "        # Connects i -> i-1 (wrapping around to N-1)\n",
        "        for i in range(n_qubits):\n",
        "            control = i\n",
        "            target = (i - 1) % n_qubits\n",
        "            qc.cry(theta[param_idx], control, target)\n",
        "            param_idx += 1\n",
        "\n",
        "    return qc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ma=ansatz(5,2)\n",
        "ma.draw(style=\"mpl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "gf6trUuHxKpZ",
        "outputId": "bd9b7449-faa9-4094-a018-28bbdfd87e66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[9]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rx(Î¸[5]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[6]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[12]) â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[8]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[10]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[16]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[17]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[13]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[14]) â”œâ”¤ Ry(Î¸[15]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                  \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "Â«q_3: â”¤ Ry(Î¸[19]) â”œ\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€\n",
              "Â«                  "
            ],
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[9]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rx(Î¸[5]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[6]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[12]) â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[8]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[10]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[16]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[17]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[13]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[14]) â”œâ”¤ Ry(Î¸[15]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                  \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "Â«q_3: â”¤ Ry(Î¸[19]) â”œ\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€\n",
              "Â«                  </pre>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.primitives import PrimitiveResult, PubResult\n",
        "from qiskit.primitives.base import BaseEstimatorV2\n",
        "from qiskit.primitives.containers.data_bin import DataBin\n",
        "from qiskit import transpile\n",
        "import numpy as np\n",
        "\n",
        "class SimpleIQMJob:\n",
        "    \"\"\"A dummy job that simply holds the result.\"\"\"\n",
        "    def __init__(self, result):\n",
        "        self._result = result\n",
        "\n",
        "    def result(self):\n",
        "        return self._result\n",
        "\n",
        "# --- THE BRIDGE CLASS ---\n",
        "class IQMBackendEstimator(BaseEstimatorV2):\n",
        "    def __init__(self, backend, options=None):\n",
        "        super().__init__()\n",
        "        self._backend = backend\n",
        "        self._options = options or {\"shots\": 100}\n",
        "\n",
        "    def run(self, pubs, precision=None):\n",
        "        if not isinstance(pubs, list): pubs = [pubs]\n",
        "        job_results = []\n",
        "\n",
        "        # 1. Prepare Circuit\n",
        "        base_circuit = pubs[0][0]\n",
        "        circuit_with_meas = base_circuit.copy()\n",
        "        if circuit_with_meas.num_clbits == 0:\n",
        "            circuit_with_meas.measure_all()\n",
        "\n",
        "        # 2. Transpile\n",
        "        transpiled_qc = transpile(circuit_with_meas, self._backend, optimization_level=3)\n",
        "\n",
        "        for pub in pubs:\n",
        "            _, observables, parameter_values = pub\n",
        "            if parameter_values.ndim == 1:\n",
        "                parameter_values = [parameter_values]\n",
        "\n",
        "            pub_expectations = []\n",
        "\n",
        "            for params in parameter_values:\n",
        "                bound_qc = transpiled_qc.assign_parameters(params)\n",
        "\n",
        "                # 3. Execute on Hardware\n",
        "                try:\n",
        "                    job = self._backend.run(bound_qc, shots=self._options[\"shots\"])\n",
        "                    result = job.result()\n",
        "                    counts = result.get_counts()\n",
        "\n",
        "                    if isinstance(counts, list): counts = counts[0]\n",
        "\n",
        "                    # 4. Calculate Expectation\n",
        "                    shots = sum(counts.values())\n",
        "                    count_0 = 0\n",
        "                    for bitstring, count in counts.items():\n",
        "                        if bitstring[-1] == '0':\n",
        "                            count_0 += count\n",
        "\n",
        "                    p0 = count_0 / shots\n",
        "                    p1 = 1 - p0\n",
        "                    pub_expectations.append(p0 - p1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Job failed: {e}\")\n",
        "                    pub_expectations.append(0.0)\n",
        "\n",
        "            data = DataBin(evs=np.array(pub_expectations), shape=(len(pub_expectations),))\n",
        "            job_results.append(PubResult(data=data))\n",
        "\n",
        "        return SimpleIQMJob(PrimitiveResult(job_results))"
      ],
      "metadata": {
        "id": "-s4fEBIFMl4K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z_JEkN9KJ-Fh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    The code below constructs the class HybridModel. It is built using the Qiskit and Pytorch library and\n",
        "    and utilizes its built-in tools, to create a model connecting classical and quantum computing.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, ansatz_circuit, num_qubits):\n",
        "        super().__init__()\n",
        "        self.feature_map = self.angle_encoding(num_qubits)\n",
        "\n",
        "        # Connecting the quantum circuit. Connecting our feature map (data) and ansatz\n",
        "        self.qc = QuantumCircuit(num_qubits)\n",
        "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
        "        self.qc.compose(ansatz_circuit, inplace=True)\n",
        "\n",
        "        # Firstly, we inicialize parameters. Our quantum model cannot tell whether the number came from ansatz or feature.\n",
        "        # That is why here we sort them into two lists. If the number came from feature_map, then it will be a feature and the other way around.\n",
        "        input_params = list(self.feature_map.parameters)\n",
        "        weight_params = list(ansatz_circuit.parameters)\n",
        "\n",
        "        '''\n",
        "        Measure the Z-operator (spin) on the very first qubit (q_0) and ignore all the other qubits.\n",
        "        Qiskit reads the string in a reversed order, that is why the Z gate is on the end.\n",
        "        SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)]) converts string into a mathematical matrix that Qiskit can use for calculations\n",
        "        Coefficient = 1 is a weight we multiply our result by. In QML it is mostly set to 1\n",
        "        '''\n",
        "\n",
        "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
        "\n",
        "        # Estimator takes ansatz, observables and parameters (data and weights), returns the Expectation value.\n",
        "        # !!!! CHANGE WHEN USING ON QUANTUM COMPUTER\n",
        "        # Needed when running quantum simulations, it should be changed when implementing on real quantum computer\n",
        "        estimator = StatevectorEstimator()\n",
        "\n",
        "        # Compute the gradients of the sampling probability by the Parameter Shift Rule.\n",
        "        gradient = ParamShiftEstimatorGradient(estimator)\n",
        "\n",
        "\n",
        "        '''\n",
        "        The EstimatorQNN\n",
        "        This class from Qiskit Machine Learning is used to instantiate the quantum neural network.\n",
        "        It leverages the Qiskit Primitives (Estimator) to efficiently calculate expectation values\n",
        "        of the quantum circuit. This allows the model to output continuous, differentiable values (gradients)\n",
        "        required for backpropagation in hybrid quantum-classical training.\n",
        "        '''\n",
        "\n",
        "        self.qnn = EstimatorQNN(\n",
        "            circuit=self.qc,\n",
        "            observables=observable,\n",
        "            input_params=input_params,\n",
        "            weight_params=weight_params,\n",
        "            estimator=estimator,\n",
        "            gradient=gradient\n",
        "        )\n",
        "\n",
        "        '''\n",
        "        TORCH CONNECTOR\n",
        "        This line initializes the TorchConnector, which serves as a bridge between Qiskit and PyTorch. It wraps the Quantum Neural Network (QNN)\n",
        "        to make it function as a standard, differentiable PyTorch module (nn.Module).\n",
        "        This integration allows the quantum parameters to be optimized using standard PyTorch tools like\n",
        "        the Adam optimizer and automatic differentiation.\n",
        "        '''\n",
        "        self.quantum_layer = TorchConnector(self.qnn)\n",
        "\n",
        "        \"\"\"\n",
        "        Creates a Feature Map circuit using Angle Encoding. It maps classical input vectors\n",
        "        to the quantum space by applying Ry(theta) rotations on each qubit,\n",
        "        where the rotation angle theta corresponds to the input feature value.\n",
        "        This effectively encodes the data into the amplitudes of the quantum state\n",
        "        \"\"\"\n",
        "\n",
        "    def angle_encoding(self, num_qubits):\n",
        "        qc_data = QuantumCircuit(num_qubits)\n",
        "        input_params = ParameterVector('x', num_qubits)\n",
        "        for i in range(num_qubits):\n",
        "            qc_data.ry(input_params[i], i)\n",
        "        return qc_data\n",
        "\n",
        "    '''\n",
        "    This function acts as the main execution path. When the model receives data,\n",
        "    the forward function passes it into the quantum layer to be processed.\n",
        "    The quantum layer calculates the result based on the current circuit parameters and returns the prediction.\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        return self.quantum_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv_mmuC3lXfL",
        "outputId": "9e92f3c1-9966-405e-a1f7-7ece226eeaf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data ready. Number of training samples: 1097\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 32\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "print(\"Loading data...\")\n",
        "\n",
        "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
        "\n",
        "y_train = 2 * y_train_raw - 1\n",
        "y_test = 2 * y_test_raw - 1\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "print(f\"Data ready. Number of training samples: {len(X_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vbZY4sy_Dzuh"
      },
      "outputs": [],
      "source": [
        "# --- Preparing the DataLoader ---\n",
        "\n",
        "# Data conversion to tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# Creating a dataset with X_train_tensor and Y_train_tensor\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Creating a DataLoader, which now automatically handles shuffle in the training loop\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "PQpegINFKm1M",
        "outputId": "eeeb5f8b-632c-4bdd-b73a-d8dad73b86fe",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training... Epochs: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1001066084.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    313\u001b[0m             )\n\u001b[1;32m    314\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/connectors/torch_connector.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# evaluate QNN gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         input_grad, weights_grad = neural_network.backward(\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0minput_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         input_grad_reshaped, weight_grad_reshaped = self._validate_backward_output(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py\u001b[0m in \u001b[0;36m_backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mQiskitMachineLearningError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Estimator job failed. {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit/primitives/primitive_job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_submitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Defining a loss function (note for Axion, it it the same as MichaÅ‚ calculated manually with diff**2)\n",
        "loss_function = torch.nn.MSELoss()\n",
        "\n",
        "# Inicializing the model\n",
        "final_ansatz = ansatz(5, 6)\n",
        "model = HybridModel(final_ansatz, 5)\n",
        "\n",
        "# Initializing the ADAM optimizer\n",
        "# Now that Our HybridModel is written in Pytorch, optimizer can access the paramiters directly\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Starting training... Epochs: {EPOCHS}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batches_count = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()           # Reset gradients\n",
        "        output = model(X_batch)         # Forward\n",
        "        loss = loss_function(output, y_batch) # Loss\n",
        "        loss.backward()                 # Backward\n",
        "        optimizer.step()                # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batches_count += 1\n",
        "\n",
        "    # Evaluation on tensors\n",
        "    with torch.no_grad(): # To test our model we turn off the gradients\n",
        "\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = loss_function(test_outputs, y_test_tensor).item()\n",
        "\n",
        "        # Calculating accuracy:\n",
        "        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\n",
        "        # Then, multiply it by two, so for True = 2.0 False = 0.0\n",
        "        # Substract 1 and the labels are either 1.0 or -1.0\n",
        "        predicted = (test_outputs > 0).float() * 2 - 1\n",
        "        correct = (predicted == y_test_tensor).sum().item()\n",
        "        test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "    avg_loss = epoch_loss / batches_count\n",
        "    train_loss_history.append(avg_loss)\n",
        "    test_loss_history.append(test_loss)\n",
        "    acc_history.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"quantum_symulator_weights.pth\")\n",
        "print(f\"âœ… Wagi zapisane do pliku: quantum_symulator_weights.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "VKpTxQgZdUGC",
        "outputId": "57862169-4e1b-481b-d629-f9e0f4f2c06c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 SCORE:  0.2905027932960894  | ACCURACY SCORE:  0.5381818181818182\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    test_outputs_tensor = model(X_test_tensor)\n",
        "    test_outputs = test_outputs_tensor.numpy()\n",
        "\n",
        "predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
        "\n",
        "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
        "c_matrix_display.plot()\n",
        "\n",
        "epochs = range(1, len(train_loss_history) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
        "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
        "plt.title('Ansatz for Simulator - Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from iqm.qiskit_iqm import IQMProvider\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "# 1. Connect to IQM\n",
        "\n",
        "try:\n",
        "    provider = IQMProvider(\"https://odra5.e-science.pl/\", token=input(\"Enter IQM Token: \"))\n",
        "    iqm_backend = provider.get_backend()\n",
        "    print(f\"Connected to backend: {iqm_backend.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Connection error: {e}\")\n",
        "\n",
        "# 2. Instantiate the Bridge\n",
        "\n",
        "hardware_estimator = IQMBackendEstimator(iqm_backend, options={\"shots\": 100})\n",
        "\n",
        "# 3. Re-create the QNN for Hardware\n",
        "print(\"Building Hardware QNN...\")\n",
        "\n",
        "# Reuse the same ansatz structure\n",
        "hw_ansatz = ansatz(4, 2)\n",
        "hw_feature_map = model.angle_encoding(4)\n",
        "\n",
        "hw_qc = QuantumCircuit(4)\n",
        "hw_qc.compose(hw_feature_map, qubits=range(4), inplace=True)\n",
        "hw_qc.compose(hw_ansatz, inplace=True)\n",
        "\n",
        "observable = SparsePauliOp.from_list([(\"I\" * 3 + \"Z\", 1)])\n",
        "\n",
        "# Create QNN with the HARDWARE ESTIMATOR\n",
        "hw_qnn = EstimatorQNN(\n",
        "    circuit=hw_qc,\n",
        "    observables=observable,\n",
        "    input_params=list(hw_feature_map.parameters),\n",
        "    weight_params=list(hw_ansatz.parameters),\n",
        "    estimator=hardware_estimator\n",
        ")\n",
        "\n",
        "# Create Torch Layer\n",
        "iqm_model = TorchConnector(hw_qnn)\n",
        "\n",
        "# 4. LOAD TRAINED WEIGHTS (CORRECTED LINE)\n",
        "iqm_model.load_state_dict(model.quantum_layer.state_dict())\n",
        "print(\"Trained weights transferred to IQM model!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "ZxK3eOwJMui4",
        "outputId": "83d62df9-cae8-48f3-b69f-5efdfef65e13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement iqm-client-qiskit (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for iqm-client-qiskit\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'iqm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-464906365.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install iqm-client-qiskit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0miqm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqiskit_iqm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIQMProvider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_networks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEstimatorQNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchConnector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'iqm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_circuit_stats(circuit, backend):\n",
        "    t_qc = transpile(circuit, backend, optimization_level=3)\n",
        "    ops = t_qc.count_ops()\n",
        "    return {\n",
        "        'Depth': t_qc.depth(),\n",
        "        'SWAPs': ops.get('swap', 0),\n",
        "        'CNOTs/CZs': ops.get('cz', 0) + ops.get('cx', 0)\n",
        "    }\n",
        "# 1. Get Circuit Stats first\n",
        "stats = get_circuit_stats(iqm_model.qc, backend)\n",
        "\n",
        "# 2. Select sample\n",
        "sample_idx = 0\n",
        "sample_input = X_test_tensor[sample_idx]\n",
        "actual_label = y_test_tensor[sample_idx].item()\n",
        "\n",
        "print(f\"ğŸš€ Sending job to IQM Spark...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = iqm_model(sample_input)\n",
        "\n",
        "predicted_label = 1 if prediction.item() > 0 else -1\n",
        "\n",
        "# --- FINAL COMPARISON TABLE ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"       HARDWARE PERFORMANCE REPORT\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Circuit Depth:      {stats['Depth']}\")\n",
        "print(f\"SWAP Gates:         {stats['SWAPs']}  <-- (Target: 0)\")\n",
        "print(f\"CZ Gates:           {stats['CNOTs/CZs']}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"IQM Raw Output:     {prediction.item():.4f}\")\n",
        "print(f\"Predicted Class:    {predicted_label}\")\n",
        "print(f\"Actual Class:       {int(actual_label)}\")\n",
        "print(f\"Confidence Level:   {abs(prediction.item()):.2%}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "PrGqgkAcNOk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IğŸ›°ï¸ Ansatz 2: Star-Topology Hardware-Efficient (IQM Spark Optimized)\n"
      ],
      "metadata": {
        "id": "VLbRLDOgEwJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Overview:**\n",
        "Ansatz 2 is a Hardware-Efficient Functional Form engineered to bypass the connectivity bottlenecks of the Odra quantum processor. While traditional ansatze assume a \"virtual\" all-to-all connectivity, this model is built as a direct mapping of the physical qubit coupling map, prioritizing gate fidelity over raw parameter count.\n",
        "##Topology Mapping:\n",
        "* **The Star Hub Configuration:** Unlike the Ring topology (Ansatz 1) which incurs a heavy SWAP-gate penalty, Ansatz 2 utilizes a Hub-and-Spoke architecture.\n",
        "* **Central Synchronizer:** QB3 (index 2) is designated as the primary entangler (Hub). By connecting QB3 directly to peripherals [0, 1, 3, 4], we achieve global information diffusion without moving quantum states across the chip.\n",
        "* **SWAP Elimination:** This design results in a zero-SWAP transpilation overhead. On a physical Odra backend, this reduces the total CNOT-equivalent count by approximately 60-80% compared to a non-mapped Ring topology.\n",
        "\n",
        "##Native Gate Optimization (CZ-Based)\n",
        "IQM Spark utilize Controlled-Z (CZ) as native entanglers.\n",
        "* **Direct Execution:** By utilizing native CZ gates instead of synthetic CRX/CRY. This prevents the accumulation of coherent errors and reduces the overall gate-pulse duration.\n",
        "* **Hybrid Expressibility:** To maintain the non-linear learning capabilities of controlled rotations, we implement a Pre-Entanglement Parameterization layer using $R_z$ and $R_y$ rotations. This effectively \"tunes\" the entanglement interaction locally before the native $CZ$ operation.\n",
        "\n",
        "## Layered Parametric Strategy\n",
        "The ansatz utilizes a 2-step iterative block (18 parameters total) designed to probe the Hilbert space symmetrically:\n",
        "* **Sub-Layer A (Z-Basis Phase Correlation):** Pairs independent $R_y$ rotations with $R_z$-tuned $CZ$ gates. This focuses on creating phase-sensitive correlations between the hub and the satellites.\n",
        "* **Sub-Layer B (Y-Basis Amplitude Correlation):** Pairs independent $R_x$ rotations with $R_y$-tuned $CZ$ gates. This simulates the effect of a $CRY$ interaction, allowing for complex amplitude redistribution while remaining hardware-native.4. Technical SpecificationsGate Set: $\\{R_x, R_y, R_z, CZ\\}$."
      ],
      "metadata": {
        "id": "dcirKZNcEz9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ansatz_Odra(n_qubits, depth):\n",
        "    \"\"\"\n",
        "    Constructs a hardware-efficient ansatz tailored for a star topology.\n",
        "    QB3 (index 2) acts as the central hub for entanglement to avoid SWAP gates.\n",
        "    Native CZ gates are used to minimize decomposition errors.\n",
        "    \"\"\"\n",
        "\n",
        "    # Each full iteration (2 layers) consumes:\n",
        "    # Layer 1: n_qubits (RY) + 4 (RZ before CZ) = 9 parameters\n",
        "    # Layer 2: n_qubits (RX) + 4 (RY before CZ) = 9 parameters\n",
        "    # Total = 18 parameters per iteration (where depth // 2 is the number of iterations)\n",
        "    params_per_iter = 18\n",
        "    total_params = params_per_iter * (depth // 2)\n",
        "    theta = ParameterVector('Î¸', total_params)\n",
        "\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    # The loop iterates (depth // 2) times to execute two-layer blocks.\n",
        "    for j in range(depth // 2):\n",
        "        offset = j * params_per_iter\n",
        "\n",
        "        # -------- Layer 1: RY + Star CZ (RZ-based) --------\n",
        "\n",
        "        # Sub-layer: Independent RY rotations on all qubits\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(theta[offset + i], i)\n",
        "\n",
        "        # Sub-layer: Entanglement using Star Topology\n",
        "        # QB3 (index 2) is the central qubit. We connect it to [0, 1, 3, 4].\n",
        "        # RZ rotations are added to maintain expressibility while using native CZ.\n",
        "        target_qubits = [0, 1, 3, 4]\n",
        "        for idx, target in enumerate(target_qubits):\n",
        "            # Using parameters offset+5 to offset+8\n",
        "            qc.rz(theta[offset + n_qubits + idx], target)\n",
        "            qc.cz(2, target)\n",
        "\n",
        "        # -------- Layer 2: RX + Star CZ (RY-based) --------\n",
        "\n",
        "        # Move the offset forward for the second layer within the same iteration\n",
        "        offset_layer2 = offset + 9\n",
        "\n",
        "        # Sub-layer: Independent RX rotations on all qubits\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(theta[offset_layer2 + i], i)\n",
        "\n",
        "        # Sub-layer: Entanglement using Star Topology\n",
        "        # RY rotations are used here to simulate the effect of a CRY-like interaction.\n",
        "        for idx, target in enumerate(target_qubits):\n",
        "            # Using parameters offset_layer2+5 to offset_layer2+8\n",
        "            qc.ry(theta[offset_layer2 + n_qubits + idx], target)\n",
        "            qc.cz(2, target)\n",
        "\n",
        "    return qc"
      ],
      "metadata": {
        "id": "--gzGz2DPLHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma=ansatz_Odra(5,2)\n",
        "ma.draw(style=\"mpl\")"
      ],
      "metadata": {
        "id": "W44R2wbLPN0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.primitives import PrimitiveResult, PubResult\n",
        "from qiskit.primitives.base import BaseEstimatorV2\n",
        "from qiskit.primitives.containers.data_bin import DataBin\n",
        "from qiskit import transpile\n",
        "import numpy as np\n",
        "\n",
        "class SimpleIQMJob:\n",
        "    \"\"\"A dummy job that simply holds the result.\"\"\"\n",
        "    def __init__(self, result):\n",
        "        self._result = result\n",
        "\n",
        "    def result(self):\n",
        "        return self._result\n",
        "\n",
        "# --- THE BRIDGE CLASS ---\n",
        "class IQMBackendEstimator(BaseEstimatorV2):\n",
        "    def __init__(self, backend, options=None):\n",
        "        super().__init__()\n",
        "        self._backend = backend\n",
        "        self._options = options or {\"shots\": 100}\n",
        "\n",
        "    def run(self, pubs, precision=None):\n",
        "        if not isinstance(pubs, list): pubs = [pubs]\n",
        "        job_results = []\n",
        "\n",
        "        # 1. Prepare Circuit\n",
        "        base_circuit = pubs[0][0]\n",
        "        circuit_with_meas = base_circuit.copy()\n",
        "        if circuit_with_meas.num_clbits == 0:\n",
        "            circuit_with_meas.measure_all()\n",
        "\n",
        "        # 2. Transpile with Hardware-Aware mapping\n",
        "        # Maps logical qubits to physical Star topology of the IQM chip.\n",
        "        star_layout = [0, 1, 2, 3, 4]\n",
        "\n",
        "        transpiled_qc = transpile(\n",
        "            circuit_with_meas,\n",
        "            self._backend,\n",
        "            initial_layout=star_layout,\n",
        "            optimization_level=3\n",
        "        )\n",
        "\n",
        "        # Log optimization results\n",
        "        gate_counts = transpiled_qc.count_ops()\n",
        "        if 'swap' in gate_counts:\n",
        "            print(f\"Warning: Transpiler added {gate_counts['swap']} SWAPs.\")\n",
        "        else:\n",
        "            print(\"Optimization Success: 0 SWAPs added.\")\n",
        "\n",
        "        for pub in pubs:\n",
        "            _, observables, parameter_values = pub\n",
        "            if parameter_values.ndim == 1:\n",
        "                parameter_values = [parameter_values]\n",
        "\n",
        "            pub_expectations = []\n",
        "\n",
        "            for params in parameter_values:\n",
        "                # Bind parameters to the already transpiled circuit\n",
        "                bound_qc = transpiled_qc.assign_parameters(params)\n",
        "\n",
        "                # 3. Execute on Hardware\n",
        "                try:\n",
        "                    job = self._backend.run(bound_qc, shots=self._options[\"shots\"])\n",
        "                    result = job.result()\n",
        "                    counts = result.get_counts()\n",
        "\n",
        "                    if isinstance(counts, list):\n",
        "                        counts = counts[0]\n",
        "\n",
        "                    # 4. Calculate Expectation Value\n",
        "                    shots = sum(counts.values())\n",
        "                    count_0 = 0\n",
        "                    for bitstring, count in counts.items():\n",
        "                        if bitstring[-1] == '0':\n",
        "                            count_0 += count\n",
        "\n",
        "                    p0 = count_0 / shots\n",
        "                    p1 = 1 - p0\n",
        "                    pub_expectations.append(p0 - p1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Job failed: {e}\")\n",
        "                    pub_expectations.append(0.0)\n",
        "\n",
        "            # DataBin must be created for each PUB\n",
        "            data = DataBin(evs=np.array(pub_expectations), shape=(len(pub_expectations),))\n",
        "            job_results.append(PubResult(data=data))\n",
        "\n",
        "        # IMPORTANT: Close all parentheses here\n",
        "        return SimpleIQMJob(PrimitiveResult(job_results))"
      ],
      "metadata": {
        "id": "nZzZFnGIPPza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, ansatz_circuit, num_qubits, backend=None):\n",
        "        super().__init__()\n",
        "        # 1. Initialize the feature map with 4 inputs but 5 qubits\n",
        "        self.feature_map = self.angle_encoding(num_qubits)\n",
        "\n",
        "        # 2. Combine feature map and ansatz\n",
        "        self.qc = QuantumCircuit(num_qubits)\n",
        "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
        "        self.qc.compose(ansatz_circuit, inplace=True)\n",
        "\n",
        "        input_params = list(self.feature_map.parameters)\n",
        "        weight_params = list(ansatz_circuit.parameters)\n",
        "\n",
        "        # 3. Define Observable (Z on the last qubit)\n",
        "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
        "\n",
        "        # 4. Choose Estimator (Hardware vs Simulation)\n",
        "        if backend:\n",
        "            # Using your custom IQM bridge\n",
        "            estimator = IQMBackendEstimator(backend, options={\"shots\": 1000})\n",
        "            gradient = None # ParamShift is too slow for real hardware training\n",
        "        else:\n",
        "            # Local simulation\n",
        "            estimator = StatevectorEstimator()\n",
        "            gradient = ParamShiftEstimatorGradient(estimator)\n",
        "\n",
        "        # 5. Build QNN\n",
        "        self.qnn = EstimatorQNN(\n",
        "            circuit=self.qc,\n",
        "            observables=observable,\n",
        "            input_params=input_params,\n",
        "            weight_params=weight_params,\n",
        "            estimator=estimator,\n",
        "            gradient=gradient\n",
        "        )\n",
        "\n",
        "        self.quantum_layer = TorchConnector(self.qnn)\n",
        "\n",
        "    def angle_encoding(self, num_qubits):\n",
        "        # We have 4 features from the dataset\n",
        "        num_features = 4\n",
        "        qc_data = QuantumCircuit(num_qubits)\n",
        "\n",
        "        # We create exactly 4 parameters to match X_batch size\n",
        "        input_params = ParameterVector('x', num_features)\n",
        "\n",
        "        for i in range(num_features):\n",
        "            # Map features to the first 4 qubits\n",
        "            qc_data.ry(input_params[i], i)\n",
        "\n",
        "        return qc_data\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.quantum_layer(x)"
      ],
      "metadata": {
        "id": "sMmIjRrUPR5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.005\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "print(\"Loading data...\")\n",
        "\n",
        "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
        "\n",
        "y_train = 2 * y_train_raw - 1\n",
        "y_test = 2 * y_test_raw - 1\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "print(f\"Data ready. Number of training samples: {len(X_train)}\")"
      ],
      "metadata": {
        "id": "c6a8_lSrPTxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preparing the DataLoader ---\n",
        "\n",
        "# Data conversion to tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "# Creating a dataset with X_train_tensor and Y_train_tensor\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Creating a DataLoader, which now automatically handles shuffle in the training loop\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "nL5hvBeEPVb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.MSELoss()\n",
        "\n",
        "\n",
        "# Change 4 to 5 because your star topology needs QB5 (index 4)\n",
        "num_qubits = 5\n",
        "\n",
        "# Initializing the model with 5 qubits\n",
        "final_ansatz = ansatz_Odra(num_qubits, 2)\n",
        "model = HybridModel(final_ansatz, num_qubits)\n",
        "\n",
        "# Initializing the ADAM optimizer\n",
        "# Now that Our HybridModel is written in Pytorch, optimizer can access the paramiters directly\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Starting training... Epochs: {EPOCHS}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batches_count = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()           # Reset gradients\n",
        "        output = model(X_batch)         # Forward\n",
        "        loss = loss_function(output, y_batch) # Loss\n",
        "        loss.backward()                 # Backward\n",
        "        optimizer.step()                # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batches_count += 1\n",
        "\n",
        "    # Evaluation on tensors\n",
        "    with torch.no_grad(): # To test our model we turn off the gradients\n",
        "\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = loss_function(test_outputs, y_test_tensor).item()\n",
        "\n",
        "        # Calculating accuracy:\n",
        "        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\n",
        "        # Then, multiply it by two, so for True = 2.0 False = 0.0\n",
        "        # Substract 1 and the labels are either 1.0 or -1.0\n",
        "        predicted = (test_outputs > 0).float() * 2 - 1\n",
        "        correct = (predicted == y_test_tensor).sum().item()\n",
        "        test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "    avg_loss = epoch_loss / batches_count\n",
        "    train_loss_history.append(avg_loss)\n",
        "    test_loss_history.append(test_loss)\n",
        "    acc_history.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"quantum_star_weights.pth\")\n",
        "print(f\"âœ… Wagi zapisane do pliku: quantum_star_weights.pth\")"
      ],
      "metadata": {
        "id": "oHEfEhwfPXto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_outputs_tensor = model(X_test_tensor)\n",
        "    test_outputs = test_outputs_tensor.numpy()\n",
        "\n",
        "predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
        "\n",
        "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
        "c_matrix_display.plot()\n",
        "\n",
        "epochs = range(1, len(train_loss_history) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
        "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
        "plt.title('IQM Spark adapted anzatz Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))"
      ],
      "metadata": {
        "id": "LudXImudPcir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from iqm.qiskit_iqm import IQMProvider\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "# 1. Connect to IQM\n",
        "\n",
        "try:\n",
        "    provider = IQMProvider(\"https://odra5.e-science.pl/\", token=input(\"Enter IQM Token: \"))\n",
        "    iqm_backend = provider.get_backend()\n",
        "    print(f\"Connected to backend: {iqm_backend.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Connection error: {e}\")\n",
        "\n",
        "# 2. Instantiate the Bridge\n",
        "\n",
        "hardware_estimator = IQMBackendEstimator(iqm_backend, options={\"shots\": 100})\n",
        "\n",
        "# 3. Re-create the QNN for Hardware\n",
        "print(\"Building Hardware QNN...\")\n",
        "\n",
        "# Reuse the same ansatz structure\n",
        "hw_ansatz = ansatz_Odra(4, 2) #(5,2)!!!????\n",
        "hw_feature_map = model.angle_encoding(4)\n",
        "\n",
        "hw_qc = QuantumCircuit(4)\n",
        "hw_qc.compose(hw_feature_map, qubits=range(4), inplace=True)\n",
        "hw_qc.compose(hw_ansatz, inplace=True)\n",
        "\n",
        "observable = SparsePauliOp.from_list([(\"I\" * 3 + \"Z\", 1)])\n",
        "\n",
        "# Create QNN with the HARDWARE ESTIMATOR\n",
        "hw_qnn = EstimatorQNN(\n",
        "    circuit=hw_qc,\n",
        "    observables=observable,\n",
        "    input_params=list(hw_feature_map.parameters),\n",
        "    weight_params=list(hw_ansatz.parameters),\n",
        "    estimator=hardware_estimator\n",
        ")\n",
        "\n",
        "# Create Torch Layer\n",
        "iqm_model = TorchConnector(hw_qnn)\n",
        "\n",
        "# 4. LOAD TRAINED WEIGHTS (CORRECTED LINE)\n",
        "iqm_model.load_state_dict(model.quantum_layer.state_dict())\n",
        "print(\"Trained weights transferred to IQM model!\")"
      ],
      "metadata": {
        "id": "f2put-w7PfGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_circuit_stats(circuit, backend):\n",
        "    t_qc = transpile(circuit, backend, optimization_level=3)\n",
        "    ops = t_qc.count_ops()\n",
        "    return {\n",
        "        'Depth': t_qc.depth(),\n",
        "        'SWAPs': ops.get('swap', 0),\n",
        "        'CNOTs/CZs': ops.get('cz', 0) + ops.get('cx', 0)\n",
        "    }\n",
        "# 1. Get Circuit Stats first\n",
        "stats = get_circuit_stats(iqm_model.qc, backend)\n",
        "\n",
        "# 2. Select sample\n",
        "sample_idx = 0\n",
        "sample_input = X_test_tensor[sample_idx]\n",
        "actual_label = y_test_tensor[sample_idx].item()\n",
        "\n",
        "print(f\"ğŸš€ Sending job to IQM Spark...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = iqm_model(sample_input)\n",
        "\n",
        "predicted_label = 1 if prediction.item() > 0 else -1\n",
        "\n",
        "# --- FINAL COMPARISON TABLE ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"       HARDWARE PERFORMANCE REPORT\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Circuit Depth:      {stats['Depth']}\")\n",
        "print(f\"SWAP Gates:         {stats['SWAPs']}  <-- (Target: 0)\")\n",
        "print(f\"CZ Gates:           {stats['CNOTs/CZs']}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"IQM Raw Output:     {prediction.item():.4f}\")\n",
        "print(f\"Predicted Class:    {predicted_label}\")\n",
        "print(f\"Actual Class:       {int(actual_label)}\")\n",
        "print(f\"Confidence Level:   {abs(prediction.item()):.2%}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "JV8MKJx1PhD-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.12 (Qiskit)",
      "language": "python",
      "name": "qiskit_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}