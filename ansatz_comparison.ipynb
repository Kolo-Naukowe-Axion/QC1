{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kolo-Naukowe-Axion/QC1/blob/main/ansatz_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLzI6vhj-pd"
      },
      "source": [
        "\n",
        "\n",
        "#**Quantum Classifier - ansatz comparison**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authors:** KoÅ‚o Naukowe Axion\n",
        "\n",
        "**Dataset:** Banknote Authentication (UCI ML Repository)\n",
        "\n",
        "**Framework:** Qiskit Machine Learning + PyTorch"
      ],
      "metadata": {
        "id": "Ulv5wxh8sV33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract**\n",
        "\n",
        "This notebook presents a comparative analysis of two different quantum variational architectures (ansatze) designed for a hybrid quantum-classical machine learning task. The primary focus is to evaluate performance differences between a standard simulator-optimized ansatz and a hardware-efficient ansatz specifically tailored for the IQM Spark (Odra) quantum computer."
      ],
      "metadata": {
        "id": "WKnf1i9AspLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Environment Setup**\n",
        "This section handles dependency installation and imports. For reproducibility, all package versions should be pinned in a production environment.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uqGchgmFtR6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install qiskit==2.1.2 qiskit_machine_learning\n",
        "%pip install ucimlrepo\n",
        "%pip install torch\n",
        "%pip install matplotlib\n",
        "#%pip install iqm-client[qiskit]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qy5f6-Mjv3in",
        "outputId": "dd70f2fa-652a-40a6-9a30-ca1059030d9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit==2.1.2 in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.2) (0.17.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.2) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.2) (0.3.8)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.2) (5.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit==2.1.2) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LKSJGRyG0ouM"
      },
      "outputs": [],
      "source": [
        "#from iqm.qiskit_iqm import IQMProvider\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit import transpile\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.primitives import StatevectorEstimator, PrimitiveResult, PubResult\n",
        "from qiskit.primitives.base import BaseEstimatorV2\n",
        "from qiskit.primitives.containers.data_bin import DataBin\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "import sys          # Standard library module for system-specific parameters and functions\n",
        "import subprocess   # Standard library module for spawning new processes\n",
        "from sklearn.preprocessing import MinMaxScaler # Importuje MinMaxScaler do skalowania danych\n",
        "from sklearn.model_selection import train_test_split # Importuje train_test_split do podziaÅ‚u danych\n",
        "from ucimlrepo import fetch_ucirepo     # Importuje fetch_ucirepo do pobierania zestawÃ³w danych z UCI ML Repository\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "enUz4SJl6Fnh"
      },
      "outputs": [],
      "source": [
        "def ensure_package(pkg_name, import_name=None):\n",
        "    import_name = import_name or pkg_name\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
        "\n",
        "# Ensure all requirements are met\n",
        "ensure_package('numpy')\n",
        "ensure_package('scikit-learn', 'sklearn')\n",
        "ensure_package('ucimlrepo')\n",
        "ensure_package('qiskit')\n",
        "\n",
        "def prepare_data():\n",
        "    \"\"\"\n",
        "    Fetches the banknote authentication dataset and returns scaled train/test splits.\n",
        "    Features are scaled to [0, pi] specifically for Angle Encoding.\n",
        "    \"\"\"\n",
        "    banknote_authentication = fetch_ucirepo(id=267)\n",
        "    X = banknote_authentication.data.features.to_numpy()\n",
        "    y = banknote_authentication.data.targets.to_numpy().ravel()\n",
        "\n",
        "    variance = X[:, 0].reshape(-1, 1)\n",
        "    skewness = X[:, 1].reshape(-1, 1)\n",
        "\n",
        "    interaction = skewness * variance\n",
        "    X_expanded = np.hstack((X, interaction))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_expanded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "\n",
        "# Global availability of data\n",
        "X_tr, X_te, y_tr, y_te = prepare_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ğŸ”¬ Ansatz 1: Global Ring Entangler (Simulation-Optimized)"
      ],
      "metadata": {
        "id": "XVh14trAwFyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Overview**\n",
        "\n",
        "This ansatz is designed to maximize expressibility and entanglement capability by leveraging a global connectivity pattern. It follows a \"Circuit-centric\" design philosophy, prioritizing high-dimensional state representation to achieve superior classification performance in ideal environments.\n",
        "\n",
        "**Technical Architecture**\n",
        "\n",
        " * **Layered Structure:** The circuit employs a dual-layer strategy consisting of\n",
        "independent rotation sub-layers ($RY$, $RX$) and sophisticated entanglement blocks.\n",
        " * **Ring Topology:** Entanglement is implemented via a circular chain where each qubit $i$ is coupled with qubit $(i+1) \\pmod n$. This ensures that information from any qubit can reach any other qubit in the shortest possible path.\n",
        " * **Parametric Controlled Rotations:** Unlike standard CNOT-based circuits, this model utilizes CRX and CRY gates. These allow the model to learn not just whether to entangle, but the intensity of the entanglement, leading to high-precision decision boundaries.\n",
        " * **Reverse-Flow Correlation:** The second sub-layer reverses the entanglement direction ($i \\to i-1$), facilitating a rapid diffusion of features across the entire register.\n",
        " * **Performance & Benchmarks:**\n",
        "    In noise-free simulations, this architecture demonstrates exceptional learning capabilities:\n",
        "      * **Accuracy:** consistently achieves **>90%** on binary classification tasks.\n",
        "      * **Flexibility:** High parameter density allows for complex non-linear mapping of input data.\n",
        "  \n",
        "**Scientific Reference**\n",
        "\n",
        "  The implementation of this ansatz is based on the architectural principles discussed in: [Quantum Machine Learning in Liquid â€“ HavlÃ­Äek et al. (2019) arXiv:1905.10876](https://https://arxiv.org/abs/1905.10876)\n",
        "  \n",
        "**The \"Hardware Gap\" (Motivation for Ansatz 2)**\n",
        "While mathematically superior, Ansatz 1 poses significant challenges for physical quantum processors like the Odra system:\n",
        "* **Connectivity Constraints:** Real hardware rarely supports a physical \"Ring.\" Connecting the first and last qubits requires multiple SWAP gates, which significantly increase circuit depth and decoherence.\n",
        "* **Gate Decomposition:** $CRX$ and $CRY$ are not native gates. On hardware, they are decomposed into multiple CNOTs and single-qubit rotations, multiplying the error rate for every single operation."
      ],
      "metadata": {
        "id": "BXTxoldF8967"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pz4kqrFfANdX"
      },
      "outputs": [],
      "source": [
        "def ansatz(n_qubits, depth):\n",
        "    \"\"\"\n",
        "    The code below constructs the ansatz. It is built using the Qiskit library\n",
        "    and utilizes its built-in tools, such as ParameterVector, to easily iterate\n",
        "    over rotation gate parameters.\n",
        "\n",
        "    The implementation assumes an even number of layers (depth). Each layer consists\n",
        "    of a sub-layer of independent gates and a sub-layer of entanglement.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a vector of learnable parameters.\n",
        "    # Total parameters = 2 * num_qubits * depth (2 * n_qubits per full loop iteration).\n",
        "    theta = ParameterVector('Î¸', 2 * n_qubits * depth)\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    param_idx = 0\n",
        "\n",
        "    # The loop iterates (depth // 2) times.\n",
        "    for j in range(depth // 2):\n",
        "\n",
        "        # -------- Layer 1 --------\n",
        "\n",
        "        # Sub-layer: Independent RY rotations\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(theta[param_idx], i)\n",
        "            param_idx += 1\n",
        "\n",
        "        # Sub-layer: Entanglement (CRX) - Ring Topology\n",
        "        # Connects i -> i+1 (wrapping around to 0 at the end)\n",
        "        for i in range(n_qubits):\n",
        "            control = i\n",
        "            target = (i + 1) % n_qubits\n",
        "            qc.crx(theta[param_idx], control, target)\n",
        "            param_idx += 1\n",
        "\n",
        "\n",
        "        # -------- Layer 2 --------\n",
        "\n",
        "        # Sub-layer: Independent RX rotations\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(theta[param_idx], i)\n",
        "            param_idx += 1\n",
        "\n",
        "        # Sub-layer: Entanglement (CRY) - Reverse Ring Topology\n",
        "        # Connects i -> i-1 (wrapping around to N-1)\n",
        "        for i in range(n_qubits):\n",
        "            control = i\n",
        "            target = (i - 1) % n_qubits\n",
        "            qc.cry(theta[param_idx], control, target)\n",
        "            param_idx += 1\n",
        "\n",
        "    return qc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ma=ansatz(5,6)\n",
        "ma.draw(style=\"mpl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gf6trUuHxKpZ",
        "outputId": "034e6cd9-6be7-4433-9695-47401218b735"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[9]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rx(Î¸[5]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[6]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[12]) â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[8]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[10]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[16]) â”œâ”¤ Ry(Î¸[20]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[17]) â”œâ”¤ Ry(Î¸[21]) â”œÂ»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[13]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[14]) â”œâ”¤ Ry(Î¸[15]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[29]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_1: â”¤ Rx(Î¸[25]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[31]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[22]) â”œâ”¤ Rx(Î¸[26]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[32]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[19]) â”œâ”¤ Ry(Î¸[23]) â”œâ”¤ Rx(Î¸[27]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[24]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[28]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[30]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[36]) â”œâ”¤ Ry(Î¸[40]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[37]) â”œâ”¤ Ry(Î¸[41]) â”œÂ»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[38]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[33]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[34]) â”œâ”¤ Ry(Î¸[35]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[49]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_1: â”¤ Rx(Î¸[45]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[51]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[42]) â”œâ”¤ Rx(Î¸[46]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[52]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[39]) â”œâ”¤ Ry(Î¸[43]) â”œâ”¤ Rx(Î¸[47]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[44]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[48]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[50]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[56]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[57]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[58]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[53]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[54]) â”œâ”¤ Ry(Î¸[55]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                  \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "Â«q_3: â”¤ Ry(Î¸[59]) â”œ\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€\n",
              "Â«                  "
            ],
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[9]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rx(Î¸[5]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[6]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[12]) â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[8]) â”œâ”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[10]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[16]) â”œâ”¤ Ry(Î¸[20]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[17]) â”œâ”¤ Ry(Î¸[21]) â”œÂ»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[13]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[14]) â”œâ”¤ Ry(Î¸[15]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[29]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_1: â”¤ Rx(Î¸[25]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[31]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[22]) â”œâ”¤ Rx(Î¸[26]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[32]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[19]) â”œâ”¤ Ry(Î¸[23]) â”œâ”¤ Rx(Î¸[27]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[24]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[28]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[30]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[36]) â”œâ”¤ Ry(Î¸[40]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[37]) â”œâ”¤ Ry(Î¸[41]) â”œÂ»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[38]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[33]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[34]) â”œâ”¤ Ry(Î¸[35]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[49]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_1: â”¤ Rx(Î¸[45]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[51]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[42]) â”œâ”¤ Rx(Î¸[46]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[52]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[39]) â”œâ”¤ Ry(Î¸[43]) â”œâ”¤ Rx(Î¸[47]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”      â”‚      Â»\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[44]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[48]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             Â»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          Â»\n",
              "Â«q_0: â”¤ Rx(Î¸[50]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[56]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[57]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[58]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[53]) â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                       Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[54]) â”œâ”¤ Ry(Î¸[55]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                  \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                  \n",
              "Â«q_2: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
              "Â«q_3: â”¤ Ry(Î¸[59]) â”œ\n",
              "Â«     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
              "Â«q_4: â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€\n",
              "Â«                  </pre>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleIQMJob:\n",
        "    \"\"\"A dummy job that simply holds the result.\"\"\"\n",
        "    def __init__(self, result):\n",
        "        self._result = result\n",
        "\n",
        "    def result(self):\n",
        "        return self._result\n",
        "\n",
        "# --- THE BRIDGE CLASS ---\n",
        "class IQMBackendEstimator(BaseEstimatorV2):\n",
        "    def __init__(self, backend, options=None):\n",
        "        super().__init__()\n",
        "        self._backend = backend\n",
        "        self._options = options or {\"shots\": 100}\n",
        "        # collecting timestamps\n",
        "        self.timestamp_history = []\n",
        "        self.total_qpu_time = 0.0  # Sum of time on quantum\n",
        "\n",
        "    def _extract_timestamps(self, result):\n",
        "        try:\n",
        "            timeline = result._metadata.get('timeline', [])\n",
        "            if not timeline:\n",
        "                return None\n",
        "\n",
        "            timestamps = {}\n",
        "            for entry in timeline:\n",
        "                timestamps[entry.status] = entry.timestamp\n",
        "\n",
        "            return timestamps\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def run(self, pubs, precision=None):\n",
        "        if not isinstance(pubs, list): pubs = [pubs]\n",
        "        job_results = []\n",
        "\n",
        "        # 1. Prepare Circuit\n",
        "        base_circuit = pubs[0][0]\n",
        "        circuit_with_meas = base_circuit.copy()\n",
        "        if circuit_with_meas.num_clbits == 0:\n",
        "            circuit_with_meas.measure_all()\n",
        "\n",
        "        # 2. Transpile\n",
        "        transpiled_qc = transpile(circuit_with_meas, self._backend, optimization_level=3)\n",
        "\n",
        "        for pub in pubs:\n",
        "            _, observables, parameter_values = pub\n",
        "            if parameter_values.ndim == 1:\n",
        "                parameter_values = [parameter_values]\n",
        "\n",
        "            pub_expectations = []\n",
        "\n",
        "            for params in parameter_values:\n",
        "                bound_qc = transpiled_qc.assign_parameters(params)\n",
        "\n",
        "                # 3. Execute on Hardware\n",
        "                try:\n",
        "                    job = self._backend.run(bound_qc, shots=self._options[\"shots\"])\n",
        "                    result = job.result()\n",
        "\n",
        "                    # ========== TIMESTAMPS (IQM timeline) ==========\n",
        "                    ts = self._extract_timestamps(result)\n",
        "                    if ts:\n",
        "                        exec_start = ts.get('execution_started')\n",
        "                        exec_end = ts.get('execution_ended')\n",
        "                        comp_start = ts.get('compilation_started')\n",
        "                        comp_end = ts.get('compilation_ended')\n",
        "                        job_created = ts.get('created')\n",
        "                        job_completed = ts.get('completed')\n",
        "\n",
        "                        if exec_start and exec_end:\n",
        "                            execution_time = (exec_end - exec_start).total_seconds()\n",
        "                            compile_time = (comp_end - comp_start).total_seconds() if comp_start and comp_end else 0\n",
        "                            job_time = (job_completed - job_created).total_seconds() if job_created and job_completed else 0\n",
        "                            self.timestamp_history.append({\n",
        "                                'execution_time_qpu': execution_time,\n",
        "                                'job_time_total': job_time,\n",
        "                                'compile_time': compile_time,\n",
        "                                'raw_timestamps': ts\n",
        "                            })\n",
        "                            self.total_qpu_time += execution_time\n",
        "\n",
        "                            print(f\"TIME ON QPU: {execution_time*1000:.2f}ms | \"\n",
        "                                  f\"Compilation: {compile_time*1000:.2f}ms | \"\n",
        "                                  f\"Job overall: {job_time:.3f}s\")\n",
        "                    # =========================================================\n",
        "\n",
        "                    counts = result.get_counts()\n",
        "\n",
        "                    if isinstance(counts, list): counts = counts[0]\n",
        "\n",
        "                    # 4. Calculate Expectation\n",
        "                    shots = sum(counts.values())\n",
        "                    count_0 = 0\n",
        "                    for bitstring, count in counts.items():\n",
        "                        if bitstring[-1] == '0':\n",
        "                            count_0 += count\n",
        "\n",
        "                    p0 = count_0 / shots\n",
        "                    p1 = 1 - p0\n",
        "                    pub_expectations.append(p0 - p1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Job failed: {e}\")\n",
        "                    pub_expectations.append(0.0)\n",
        "\n",
        "            data = DataBin(evs=np.array(pub_expectations), shape=(len(pub_expectations),))\n",
        "            job_results.append(PubResult(data=data))\n",
        "\n",
        "        return SimpleIQMJob(PrimitiveResult(job_results))\n",
        "\n",
        "    def print_timing_summary(self):\n",
        "        \"\"\"Detailed summary.\"\"\"\n",
        "        if not self.timestamp_history:\n",
        "            print(\"Brak danych o timestampach.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"DETAILED SUMMARY OF THE TIMESTAMPS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Number of executed jobs: {len(self.timestamp_history)}\")\n",
        "\n",
        "        qpu_times = []\n",
        "        compile_times = []\n",
        "        queue_times = []\n",
        "        network_times = []\n",
        "\n",
        "        for t in self.timestamp_history:\n",
        "            ts = t['raw_timestamps']\n",
        "\n",
        "            # QPU\n",
        "            if ts.get('execution_started') and ts.get('execution_ended'):\n",
        "                qpu_times.append((ts['execution_ended'] - ts['execution_started']).total_seconds())\n",
        "\n",
        "            # Compilation\n",
        "            if ts.get('compilation_started') and ts.get('compilation_ended'):\n",
        "                compile_times.append((ts['compilation_ended'] - ts['compilation_started']).total_seconds())\n",
        "\n",
        "            # Queue (waiting for QPU)\n",
        "            if ts.get('pending_execution') and ts.get('execution_started'):\n",
        "                queue_times.append((ts['execution_started'] - ts['pending_execution']).total_seconds())\n",
        "\n",
        "            # (created->received + ready->completed)\n",
        "            net_time = 0\n",
        "            if ts.get('created') and ts.get('received'):\n",
        "                net_time += (ts['received'] - ts['created']).total_seconds()\n",
        "            if ts.get('ready') and ts.get('completed'):\n",
        "                net_time += (ts['completed'] - ts['ready']).total_seconds()\n",
        "            network_times.append(net_time)\n",
        "\n",
        "        print(f\"\\nTIME ON QPU :     {sum(qpu_times)*1000:8.2f} ms  (mean: {np.mean(qpu_times)*1000:.2f} ms/job)\")\n",
        "        print(f\"Compilation :           {sum(compile_times)*1000:8.2f} ms  (mean: {np.mean(compile_times)*1000:.2f} ms/job)\")\n",
        "        print(f\"Queue (wait QPU) :   {sum(queue_times)*1000:8.2f} ms  (mean: {np.mean(queue_times)*1000:.2f} ms/job)\")\n",
        "        print(f\"(upload+down) :   {sum(network_times)*1000:8.2f} ms  (mean: {np.mean(network_times)*1000:.2f} ms/job)\")\n",
        "\n",
        "        total_measured = sum(qpu_times) + sum(compile_times) + sum(queue_times) + sum(network_times)\n",
        "        total_job = sum(t['job_time_total'] for t in self.timestamp_history)\n",
        "        other = total_job - total_measured\n",
        "\n",
        "        print(f\"Others (validation etc): {other*1000:8.2f} ms\")\n",
        "        print(f\"\\nTIME OVERALL:       {total_job*1000:8.2f} ms ({total_job:.3f} s)\")\n",
        "\n",
        "        print(\"\\n\" + \"-\"*40)\n",
        "        print(\"PERCENTAGE DISTRIBUTION: \")\n",
        "        print(f\"  QPU:        {100*sum(qpu_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Compilation: {100*sum(compile_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Queue:    {100*sum(queue_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Network:       {100*sum(network_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Others:       {100*other/total_job:5.1f}%\")\n",
        "        print(\"=\"*60 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "-s4fEBIFMl4K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z_JEkN9KJ-Fh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    The code below constructs the class HybridModel. It is built using the Qiskit and Pytorch library and\n",
        "    and utilizes its built-in tools, to create a model connecting classical and quantum computing.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, ansatz_circuit, num_qubits):\n",
        "        super().__init__()\n",
        "        self.feature_map = self.angle_encoding(num_qubits)\n",
        "\n",
        "        # Connecting the quantum circuit. Connecting our feature map (data) and ansatz\n",
        "        self.qc = QuantumCircuit(num_qubits)\n",
        "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
        "        self.qc.compose(ansatz_circuit, inplace=True)\n",
        "\n",
        "        # Firstly, we inicialize parameters. Our quantum model cannot tell whether the number came from ansatz or feature.\n",
        "        # That is why here we sort them into two lists. If the number came from feature_map, then it will be a feature and the other way around.\n",
        "        input_params = list(self.feature_map.parameters)\n",
        "        weight_params = list(ansatz_circuit.parameters)\n",
        "\n",
        "        '''\n",
        "        Measure the Z-operator (spin) on the very first qubit (q_0) and ignore all the other qubits.\n",
        "        Qiskit reads the string in a reversed order, that is why the Z gate is on the end.\n",
        "        SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)]) converts string into a mathematical matrix that Qiskit can use for calculations\n",
        "        Coefficient = 1 is a weight we multiply our result by. In QML it is mostly set to 1\n",
        "        '''\n",
        "\n",
        "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
        "\n",
        "        # Estimator takes ansatz, observables and parameters (data and weights), returns the Expectation value.\n",
        "        # !!!! CHANGE WHEN USING ON QUANTUM COMPUTER\n",
        "        # Needed when running quantum simulations, it should be changed when implementing on real quantum computer\n",
        "        estimator = StatevectorEstimator()\n",
        "\n",
        "        # Compute the gradients of the sampling probability by the Parameter Shift Rule.\n",
        "        gradient = ParamShiftEstimatorGradient(estimator)\n",
        "\n",
        "\n",
        "        '''\n",
        "        The EstimatorQNN\n",
        "        This class from Qiskit Machine Learning is used to instantiate the quantum neural network.\n",
        "        It leverages the Qiskit Primitives (Estimator) to efficiently calculate expectation values\n",
        "        of the quantum circuit. This allows the model to output continuous, differentiable values (gradients)\n",
        "        required for backpropagation in hybrid quantum-classical training.\n",
        "        '''\n",
        "\n",
        "        self.qnn = EstimatorQNN(\n",
        "            circuit=self.qc,\n",
        "            observables=observable,\n",
        "            input_params=input_params,\n",
        "            weight_params=weight_params,\n",
        "            estimator=estimator,\n",
        "            gradient=gradient\n",
        "        )\n",
        "\n",
        "        '''\n",
        "        TORCH CONNECTOR\n",
        "        This line initializes the TorchConnector, which serves as a bridge between Qiskit and PyTorch. It wraps the Quantum Neural Network (QNN)\n",
        "        to make it function as a standard, differentiable PyTorch module (nn.Module).\n",
        "        This integration allows the quantum parameters to be optimized using standard PyTorch tools like\n",
        "        the Adam optimizer and automatic differentiation.\n",
        "        '''\n",
        "        self.quantum_layer = TorchConnector(self.qnn)\n",
        "\n",
        "        \"\"\"\n",
        "        Creates a Feature Map circuit using Angle Encoding. It maps classical input vectors\n",
        "        to the quantum space by applying Ry(theta) rotations on each qubit,\n",
        "        where the rotation angle theta corresponds to the input feature value.\n",
        "        This effectively encodes the data into the amplitudes of the quantum state\n",
        "        \"\"\"\n",
        "\n",
        "    def angle_encoding(self, num_qubits):\n",
        "        qc_data = QuantumCircuit(num_qubits)\n",
        "        input_params = ParameterVector('x', num_qubits)\n",
        "        for i in range(num_qubits):\n",
        "            qc_data.ry(input_params[i], i)\n",
        "        return qc_data\n",
        "\n",
        "    '''\n",
        "    This function acts as the main execution path. When the model receives data,\n",
        "    the forward function passes it into the quantum layer to be processed.\n",
        "    The quantum layer calculates the result based on the current circuit parameters and returns the prediction.\n",
        "    '''\n",
        "    def forward(self, x):\n",
        "        return self.quantum_layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv_mmuC3lXfL",
        "outputId": "dc24ddd2-06d8-4c16-e8a3-c12e7230406f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data ready. Number of training samples: 1097\n"
          ]
        }
      ],
      "source": [
        "'''EPOCHS = 32\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "print(\"Loading data...\")\n",
        "'''\n",
        "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
        "\n",
        "y_train = 2 * y_train_raw - 1\n",
        "y_test = 2 * y_test_raw - 1\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "print(f\"Data ready. Number of training samples: {len(X_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vbZY4sy_Dzuh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5243c94b-7423-49b1-ca55-aba0a24a1fc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Creating a dataset with X_train_tensor and Y_train_tensor\\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\\n\\n# Creating a DataLoader, which now automatically handles shuffle in the training loop\\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# --- Preparing the DataLoader ---\n",
        "\n",
        "# Data conversion to tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "'''\n",
        "# Creating a dataset with X_train_tensor and Y_train_tensor\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Creating a DataLoader, which now automatically handles shuffle in the training loop\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "PQpegINFKm1M",
        "outputId": "4aa89945-5d72-4a62-bcdd-5ab09ca89ee2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Weights loaded successfully. Starting evaluation...\n",
            "--- RESULTS FOR LOADED WEIGHTS ---\n",
            "Test Accuracy: 0.9164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Initializing the ADAM optimizer\\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\\n\\nprint(f\"Starting training... Epochs: {EPOCHS}\")\\n\\nfor epoch in range(EPOCHS):\\n    model.train()\\n    epoch_loss = 0.0\\n    batches_count = 0\\n\\n    for X_batch, y_batch in train_loader:\\n\\n        optimizer.zero_grad()           # Reset gradients\\n        output = model(X_batch)         # Forward\\n        loss = loss_function(output, y_batch) # Loss\\n        loss.backward()                 # Backward\\n        optimizer.step()                # Update weights\\n\\n        epoch_loss += loss.item()\\n        batches_count += 1\\n\\n    # Evaluation on tensors\\n    with torch.no_grad(): # To test our model we turn off the gradients\\n\\n        test_outputs = model(X_test_tensor)\\n        test_loss = loss_function(test_outputs, y_test_tensor).item()\\n\\n        # Calculating accuracy:\\n        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\\n        # Then, multiply it by two, so for True = 2.0 False = 0.0\\n        # Substract 1 and the labels are either 1.0 or -1.0\\n        predicted = (test_outputs > 0).float() * 2 - 1\\n        correct = (predicted == y_test_tensor).sum().item()\\n        test_accuracy = correct / len(y_test_tensor)\\n\\n    avg_loss = epoch_loss / batches_count\\n    train_loss_history.append(avg_loss)\\n    test_loss_history.append(test_loss)\\n    acc_history.append(test_accuracy)\\n\\n    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\\n\\n\\ntorch.save(model.state_dict(), \"quantum_symulator_weights.pth\")\\nprint(f\"âœ… Weights saved: quantum_symulator_weights.pth\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "loss_function = torch.nn.MSELoss()\n",
        "\n",
        "# Inicializing the model\n",
        "final_ansatz = ansatz(5, 6)\n",
        "model = HybridModel(final_ansatz, 5)\n",
        "\n",
        "model.load_state_dict(torch.load(\"classic_ansatz_weights.pth\"))\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ… Weights loaded successfully. Starting evaluation...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "\n",
        "    predicted = (test_outputs > 0).float() * 2 - 1\n",
        "    correct = (predicted == y_test_tensor).sum().item()\n",
        "    test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "print(f\"--- RESULTS FOR LOADED WEIGHTS ---\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "'''\n",
        "# Initializing the ADAM optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Starting training... Epochs: {EPOCHS}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batches_count = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()           # Reset gradients\n",
        "        output = model(X_batch)         # Forward\n",
        "        loss = loss_function(output, y_batch) # Loss\n",
        "        loss.backward()                 # Backward\n",
        "        optimizer.step()                # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batches_count += 1\n",
        "\n",
        "    # Evaluation on tensors\n",
        "    with torch.no_grad(): # To test our model we turn off the gradients\n",
        "\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = loss_function(test_outputs, y_test_tensor).item()\n",
        "\n",
        "        # Calculating accuracy:\n",
        "        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\n",
        "        # Then, multiply it by two, so for True = 2.0 False = 0.0\n",
        "        # Substract 1 and the labels are either 1.0 or -1.0\n",
        "        predicted = (test_outputs > 0).float() * 2 - 1\n",
        "        correct = (predicted == y_test_tensor).sum().item()\n",
        "        test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "    avg_loss = epoch_loss / batches_count\n",
        "    train_loss_history.append(avg_loss)\n",
        "    test_loss_history.append(test_loss)\n",
        "    acc_history.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"quantum_symulator_weights.pth\")\n",
        "print(f\"âœ… Weights saved: quantum_symulator_weights.pth\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "VKpTxQgZdUGC",
        "outputId": "c9125028-0ae0-4b78-f766-ce11c9dcf696"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Plot 1: Loss\\nplt.subplot(1, 2, 1)\\nplt.plot(epochs, train_loss_history, label=\\'Train Loss\\', color=\\'blue\\')\\nplt.plot(epochs, test_loss_history, label=\\'Test Loss\\', color=\\'red\\', linestyle=\\'--\\')\\nplt.title(\\'Ansatz for Simulator - Loss Over Epochs\\')\\nplt.xlabel(\\'Epochs\\')\\nplt.ylabel(\\'Loss\\')\\nplt.legend()\\nplt.grid(True)\\n\\n# Plot 2: Accuracy\\nplt.subplot(1, 2, 2)\\nplt.plot(epochs, acc_history, label=\\'Test Accuracy\\', color=\\'green\\')\\nplt.title(\\'Accuracy Over Epochs\\')\\nplt.xlabel(\\'Epochs\\')\\nplt.ylabel(\\'Accuracy\\')\\nplt.legend()\\nplt.grid(True)\\n\\nplt.show()\\n\\nprint(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    test_outputs_tensor = model(X_test_tensor)\n",
        "    test_outputs = test_outputs_tensor.numpy()\n",
        "\n",
        "predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
        "\n",
        "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
        "c_matrix_display.plot()\n",
        "\n",
        "#epochs = range(1, len(train_loss_history) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "'''# Plot 1: Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
        "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
        "plt.title('Ansatz for Simulator - Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))'''''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Connect to IQM\n",
        "# ---------------------------------------------------------\n",
        "try:\n",
        "    # Replace URL/Token as needed\n",
        "    provider = IQMProvider(\"https://odra5.e-science.pl/\", token=input(\"Enter IQM Token: \"))\n",
        "    iqm_backend = provider.get_backend()\n",
        "    print(f\"Connected to backend: {iqm_backend.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Connection error: {e}\")\n",
        "    # Stop execution if connection fails (optional safety)\n",
        "    exit()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Instantiate the Bridge & QNN\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Create the hardware estimator\n",
        "SHOTS = 100\n",
        "hardware_estimator = IQMBackendEstimator(iqm_backend, options={\"shots\": SHOTS})\n",
        "\n",
        "print(\"Building Hardware QNN for 5 Qubits...\")\n",
        "\n",
        "# CONFIGURATION\n",
        "N_QUBITS = 5\n",
        "DEPTH = 6  # Must be divisible by 2 based on the ansatz logic\n",
        "\n",
        "# Build Circuit Components\n",
        "hw_ansatz = ansatz(N_QUBITS, DEPTH)\n",
        "\n",
        "hw_feature_map = model.angle_encoding(N_QUBITS)\n",
        "\n",
        "hw_qc = QuantumCircuit(N_QUBITS)\n",
        "hw_qc.compose(hw_feature_map, qubits=range(N_QUBITS), inplace=True)\n",
        "hw_qc.compose(hw_ansatz, inplace=True)\n",
        "\n",
        "# Observable for 5 Qubits\n",
        "# \"IIIIZ\" measures Qubit 0 (Qiskit is little-endian: q4, q3, q2, q1, q0)\n",
        "observable = SparsePauliOp.from_list([(\"I\" * (N_QUBITS - 1) + \"Z\", 1)])\n",
        "\n",
        "# Create QNN with the HARDWARE ESTIMATOR\n",
        "hw_qnn = EstimatorQNN(\n",
        "    circuit=hw_qc,\n",
        "    observables=observable,\n",
        "    input_params=list(hw_feature_map.parameters),\n",
        "    weight_params=list(hw_ansatz.parameters),\n",
        "    estimator=hardware_estimator\n",
        ")\n",
        "\n",
        "# Create Torch Layer\n",
        "iqm_model = TorchConnector(hw_qnn)\n",
        "\n",
        "# LOAD TRAINED WEIGHTS\n",
        "# ---------------------------------------------------------\n",
        "print(\"Loading weights from file...\")\n",
        "file_path = \"classic_ansatz_weights.pth\"\n",
        "\n",
        "try:\n",
        "    state_dict = torch.load(file_path)\n",
        "\n",
        "    if \"weight\" in state_dict:\n",
        "        iqm_model.load_state_dict(state_dict)\n",
        "    elif \"quantum_layer.weight\" in state_dict:\n",
        "        with torch.no_grad():\n",
        "            iqm_model.weight.copy_(state_dict[\"quantum_layer.weight\"])\n",
        "    else:\n",
        "        iqm_model.load_state_dict(state_dict)\n",
        "\n",
        "    print(f\"âœ… Weights from {file_path} loaded successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n[!] Error: {e}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ZxK3eOwJMui4",
        "outputId": "4de11846-0e0b-41e5-e6ed-7ac452baa8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connection error: name 'IQMProvider' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'iqm_backend' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-776636419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Create the hardware estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mSHOTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mhardware_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIQMBackendEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miqm_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"shots\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSHOTS\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building Hardware QNN for 5 Qubits...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iqm_backend' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_circuit_stats(circuit, backend):\n",
        "    # Transpile to see how the hardware actually executes it\n",
        "    t_qc = transpile(circuit, backend, optimization_level=3)\n",
        "    ops = t_qc.count_ops()\n",
        "    return {\n",
        "        'Depth': t_qc.depth(),\n",
        "        'SWAPs': ops.get('swap', 0),\n",
        "        'CNOTs/CZs': ops.get('cz', 0) + ops.get('cx', 0)\n",
        "    }\n",
        "\n",
        "qnn_circuit = iqm_model.neural_network.circuit\n",
        "stats = get_circuit_stats(qnn_circuit, iqm_backend)\n",
        "\n",
        "#Select sample\n",
        "sample_idx = 67\n",
        "sample_input = X_test_tensor[sample_idx]\n",
        "actual_label = y_test_tensor[sample_idx].item()\n",
        "\n",
        "print(f\"Sending job to IQM Spark...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = iqm_model(sample_input)\n",
        "\n",
        "predicted_label = 1 if prediction.item() > 0 else -1\n",
        "\n",
        "# --- FINAL COMPARISON TABLE ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"        HARDWARE PERFORMANCE REPORT\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Circuit Depth:      {stats['Depth']}\")\n",
        "print(f\"SWAP Gates:         {stats['SWAPs']}  <-- (Target: 0)\")\n",
        "print(f\"CZ Gates:           {stats['CNOTs/CZs']}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"IQM Raw Output:     {prediction.item():.4f}\")\n",
        "print(f\"Predicted Class:    {predicted_label}\")\n",
        "print(f\"Actual Class:       {int(actual_label)}\")\n",
        "print(f\"Confidence Level:   {abs(prediction.item()):.2%}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "PrGqgkAcNOk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ğŸ›°ï¸ Ansatz 2: Star-Topology Hardware-Efficient (IQM Spark Optimized)\n"
      ],
      "metadata": {
        "id": "VLbRLDOgEwJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview:**\n",
        "Ansatz 2 is a Hardware-Efficient Functional Form engineered to bypass the connectivity bottlenecks of the Odra quantum processor. While traditional ansatze assume a \"virtual\" all-to-all connectivity, this model is built as a direct mapping of the physical qubit coupling map, prioritizing gate fidelity over raw parameter count.\n",
        "Topology Mapping:\n",
        "* **The Star Hub Configuration:** Unlike the Ring topology (Ansatz 1) which incurs a heavy SWAP-gate penalty, Ansatz 2 utilizes a Hub-and-Spoke architecture.\n",
        "* **Central Synchronizer:** QB3 (index 2) is designated as the primary entangler (Hub). By connecting QB3 directly to peripherals [0, 1, 3, 4], we achieve global information diffusion without moving quantum states across the chip.\n",
        "* **SWAP Elimination:** This design results in a zero-SWAP transpilation overhead. On a physical Odra backend, this reduces the total CNOT-equivalent count by approximately 60-80% compared to a non-mapped Ring topology.\n",
        "\n",
        "**Native Gate Optimization (CZ-Based)**\n",
        "IQM Spark utilize Controlled-Z (CZ) as native entanglers.\n",
        "* **Direct Execution:** By utilizing native CZ gates instead of synthetic CRX/CRY. This prevents the accumulation of coherent errors and reduces the overall gate-pulse duration.\n",
        "* **Hybrid Expressibility:** To maintain the non-linear learning capabilities of controlled rotations, we implement a Pre-Entanglement Parameterization layer using $R_z$ and $R_y$ rotations. This effectively \"tunes\" the entanglement interaction locally before the native $CZ$ operation.\n",
        "\n",
        "**Layered Parametric Strategy**\n",
        "The ansatz utilizes a 2-step iterative block (18 parameters total) designed to probe the Hilbert space symmetrically:\n",
        "* **Sub-Layer A (Z-Basis Phase Correlation):** Pairs independent $R_y$ rotations with $R_z$-tuned $CZ$ gates. This focuses on creating phase-sensitive correlations between the hub and the satellites.\n",
        "* **Sub-Layer B (Y-Basis Amplitude Correlation):** Pairs independent $R_x$ rotations with $R_y$-tuned $CZ$ gates. This simulates the effect of a $CRY$ interaction, allowing for complex amplitude redistribution while remaining hardware-native.4. Technical SpecificationsGate Set: $\\{R_x, R_y, R_z, CZ\\}$."
      ],
      "metadata": {
        "id": "dcirKZNcEz9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ansatz_Odra(n_qubits, depth):\n",
        "    \"\"\"\n",
        "    Constructs a hardware-efficient ansatz tailored for a star topology.\n",
        "    QB3 (index 2) acts as the central hub for entanglement to avoid SWAP gates.\n",
        "    Native CZ gates are used to minimize decomposition errors.\n",
        "    \"\"\"\n",
        "\n",
        "    # Each full iteration (2 layers) consumes:\n",
        "    # Layer 1: n_qubits (RY) + 4 (RZ before CZ) = 9 parameters\n",
        "    # Layer 2: n_qubits (RX) + 4 (RY before CZ) = 9 parameters\n",
        "    # Total = 18 parameters per iteration (where depth // 2 is the number of iterations)\n",
        "    params_per_iter = 18\n",
        "    total_params = params_per_iter * (depth // 2)\n",
        "    theta = ParameterVector('Î¸', total_params)\n",
        "\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    # The loop iterates (depth // 2) times to execute two-layer blocks.\n",
        "    for j in range(depth // 2):\n",
        "        offset = j * params_per_iter\n",
        "\n",
        "        # -------- Layer 1: RY + Star CZ (RZ-based) --------\n",
        "\n",
        "        # Sub-layer: Independent RY rotations on all qubits\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(theta[offset + i], i)\n",
        "\n",
        "        # Sub-layer: Entanglement using Star Topology\n",
        "        # QB3 (index 2) is the central qubit. We connect it to [0, 1, 3, 4].\n",
        "        # RZ rotations are added to maintain expressibility while using native CZ.\n",
        "        target_qubits = [0, 1, 3, 4]\n",
        "        for idx, target in enumerate(target_qubits):\n",
        "            # Using parameters offset+5 to offset+8\n",
        "            qc.rz(theta[offset + n_qubits + idx], target)\n",
        "            qc.cz(2, target)\n",
        "\n",
        "        # -------- Layer 2: RX + Star CZ (RY-based) --------\n",
        "\n",
        "        # Move the offset forward for the second layer within the same iteration\n",
        "        offset_layer2 = offset + 9\n",
        "\n",
        "        # Sub-layer: Independent RX rotations on all qubits\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(theta[offset_layer2 + i], i)\n",
        "\n",
        "        # Sub-layer: Entanglement using Star Topology\n",
        "        # RY rotations are used here to simulate the effect of a CRY-like interaction.\n",
        "        for idx, target in enumerate(target_qubits):\n",
        "            # Using parameters offset_layer2+5 to offset_layer2+8\n",
        "            qc.ry(theta[offset_layer2 + n_qubits + idx], target)\n",
        "            qc.cz(2, target)\n",
        "\n",
        "    return qc"
      ],
      "metadata": {
        "id": "--gzGz2DPLHU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma=ansatz_Odra(5,6)\n",
        "ma.draw(style=\"mpl\")"
      ],
      "metadata": {
        "id": "W44R2wbLPN0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "00eb762d-4edf-4844-e8b5-9d0e41cf46ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”¤ Rz(Î¸[5]) â”œâ”€â– â”€â”¤ Rx(Î¸[9]) â”œâ”¤ Ry(Î¸[14]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rz(Î¸[6]) â”œâ”€â”¼â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[10]) â”œâ”¤ Ry(Î¸[15]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚            â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”¤ Rz(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                  â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”¤ Rz(Î¸[8]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œâ”¤ Rz(Î¸[23]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[19]) â”œâ”¤ Rz(Î¸[24]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[12]) â”œâ”¤ Ry(Î¸[16]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[13]) â”œâ”¤ Ry(Î¸[17]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[27]) â”œâ”¤ Ry(Î¸[32]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[28]) â”œâ”¤ Ry(Î¸[33]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[20]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[21]) â”œâ”¤ Rz(Î¸[25]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Ry(Î¸[22]) â”œâ”¤ Rz(Î¸[26]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[36]) â”œâ”¤ Rz(Î¸[41]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[37]) â”œâ”¤ Rz(Î¸[42]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Rx(Î¸[29]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[30]) â”œâ”¤ Ry(Î¸[34]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[31]) â”œâ”¤ Ry(Î¸[35]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[45]) â”œâ”¤ Ry(Î¸[50]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[46]) â”œâ”¤ Ry(Î¸[51]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[38]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[39]) â”œâ”¤ Rz(Î¸[43]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Ry(Î¸[40]) â”œâ”¤ Rz(Î¸[44]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                                        \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                        â”‚               \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚       â”‚       \n",
              "Â«q_2: â”¤ Rx(Î¸[47]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â– â”€â”€â– â”€\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚ \n",
              "Â«q_3: â”¤ Rx(Î¸[48]) â”œâ”¤ Ry(Î¸[52]) â”œâ”€â”€â”€â”€â– â”€â”€â”¼â”€\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚ \n",
              "Â«q_4: â”¤ Rx(Î¸[49]) â”œâ”¤ Ry(Î¸[53]) â”œâ”€â”€â”€â”€â”€â”€â”€â– â”€\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         "
            ],
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "q_0: â”¤ Ry(Î¸[0]) â”œâ”¤ Rz(Î¸[5]) â”œâ”€â– â”€â”¤ Rx(Î¸[9]) â”œâ”¤ Ry(Î¸[14]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "q_1: â”¤ Ry(Î¸[1]) â”œâ”¤ Rz(Î¸[6]) â”œâ”€â”¼â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[10]) â”œâ”¤ Ry(Î¸[15]) â”œÂ»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "q_2: â”¤ Ry(Î¸[2]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚            â”‚      Â»\n",
              "q_3: â”¤ Ry(Î¸[3]) â”œâ”¤ Rz(Î¸[7]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                  â”‚      Â»\n",
              "q_4: â”¤ Ry(Î¸[4]) â”œâ”¤ Rz(Î¸[8]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[18]) â”œâ”¤ Rz(Î¸[23]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[19]) â”œâ”¤ Rz(Î¸[24]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Rx(Î¸[11]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[12]) â”œâ”¤ Ry(Î¸[16]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[13]) â”œâ”¤ Ry(Î¸[17]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[27]) â”œâ”¤ Ry(Î¸[32]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[28]) â”œâ”¤ Ry(Î¸[33]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[20]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[21]) â”œâ”¤ Rz(Î¸[25]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Ry(Î¸[22]) â”œâ”¤ Rz(Î¸[26]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[36]) â”œâ”¤ Rz(Î¸[41]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Ry(Î¸[37]) â”œâ”¤ Rz(Î¸[42]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Rx(Î¸[29]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Rx(Î¸[30]) â”œâ”¤ Ry(Î¸[34]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Rx(Î¸[31]) â”œâ”¤ Ry(Î¸[35]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             Â»\n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[45]) â”œâ”¤ Ry(Î¸[50]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«                        â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â»\n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”¤ Rx(Î¸[46]) â”œâ”¤ Ry(Î¸[51]) â”œÂ»\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚            â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â»\n",
              "Â«q_2: â”¤ Ry(Î¸[38]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚            â”‚      Â»\n",
              "Â«q_3: â”¤ Ry(Î¸[39]) â”œâ”¤ Rz(Î¸[43]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                â”‚      Â»\n",
              "Â«q_4: â”¤ Ry(Î¸[40]) â”œâ”¤ Rz(Î¸[44]) â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€Â»\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       Â»\n",
              "Â«                                        \n",
              "Â«q_0: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«                        â”‚               \n",
              "Â«q_1: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€\n",
              "Â«     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚       â”‚       \n",
              "Â«q_2: â”¤ Rx(Î¸[47]) â”œâ”€â”€â”€â”€â”€â”€â– â”€â”€â”€â”€â”€â”€â”€â– â”€â”€â– â”€â”€â– â”€\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚ \n",
              "Â«q_3: â”¤ Rx(Î¸[48]) â”œâ”¤ Ry(Î¸[52]) â”œâ”€â”€â”€â”€â– â”€â”€â”¼â”€\n",
              "Â«     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚ \n",
              "Â«q_4: â”¤ Rx(Î¸[49]) â”œâ”¤ Ry(Î¸[53]) â”œâ”€â”€â”€â”€â”€â”€â”€â– â”€\n",
              "Â«     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         </pre>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleIQMJob:\n",
        "    \"\"\"A dummy job that simply holds the result.\"\"\"\n",
        "    def __init__(self, result):\n",
        "        self._result = result\n",
        "\n",
        "    def result(self):\n",
        "        return self._result\n",
        "\n",
        "# --- THE BRIDGE CLASS ---\n",
        "class IQMBackendEstimator(BaseEstimatorV2):\n",
        "    def __init__(self, backend, options=None):\n",
        "        super().__init__()\n",
        "        self._backend = backend\n",
        "        self._options = options or {\"shots\": 100}\n",
        "        # collecting timestamps\n",
        "        self.timestamp_history = []\n",
        "        self.total_qpu_time = 0.0  # Sum of time on quantum\n",
        "\n",
        "    def _extract_timestamps(self, result):\n",
        "        try:\n",
        "            timeline = result._metadata.get('timeline', [])\n",
        "            if not timeline:\n",
        "                return None\n",
        "\n",
        "            timestamps = {}\n",
        "            for entry in timeline:\n",
        "                timestamps[entry.status] = entry.timestamp\n",
        "\n",
        "            return timestamps\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    def run(self, pubs, precision=None):\n",
        "        if not isinstance(pubs, list): pubs = [pubs]\n",
        "        job_results = []\n",
        "\n",
        "        # 1. Prepare Circuit\n",
        "        base_circuit = pubs[0][0]\n",
        "        circuit_with_meas = base_circuit.copy()\n",
        "        if circuit_with_meas.num_clbits == 0:\n",
        "            circuit_with_meas.measure_all()\n",
        "\n",
        "        # 2. Transpile\n",
        "        transpiled_qc = transpile(circuit_with_meas, self._backend, optimization_level=3)\n",
        "\n",
        "        for pub in pubs:\n",
        "            _, observables, parameter_values = pub\n",
        "            if parameter_values.ndim == 1:\n",
        "                parameter_values = [parameter_values]\n",
        "\n",
        "            pub_expectations = []\n",
        "\n",
        "            for params in parameter_values:\n",
        "                bound_qc = transpiled_qc.assign_parameters(params)\n",
        "\n",
        "                # 3. Execute on Hardware\n",
        "                try:\n",
        "                    job = self._backend.run(bound_qc, shots=self._options[\"shots\"])\n",
        "                    result = job.result()\n",
        "\n",
        "                    # ========== TIMESTAMPS (IQM timeline) ==========\n",
        "                    ts = self._extract_timestamps(result)\n",
        "                    if ts:\n",
        "                        exec_start = ts.get('execution_started')\n",
        "                        exec_end = ts.get('execution_ended')\n",
        "                        comp_start = ts.get('compilation_started')\n",
        "                        comp_end = ts.get('compilation_ended')\n",
        "                        job_created = ts.get('created')\n",
        "                        job_completed = ts.get('completed')\n",
        "\n",
        "                        if exec_start and exec_end:\n",
        "                            execution_time = (exec_end - exec_start).total_seconds()\n",
        "                            compile_time = (comp_end - comp_start).total_seconds() if comp_start and comp_end else 0\n",
        "                            job_time = (job_completed - job_created).total_seconds() if job_created and job_completed else 0\n",
        "                            self.timestamp_history.append({\n",
        "                                'execution_time_qpu': execution_time,\n",
        "                                'job_time_total': job_time,\n",
        "                                'compile_time': compile_time,\n",
        "                                'raw_timestamps': ts\n",
        "                            })\n",
        "                            self.total_qpu_time += execution_time\n",
        "\n",
        "                            print(f\"TIME ON QPU: {execution_time*1000:.2f}ms | \"\n",
        "                                  f\"Compilation: {compile_time*1000:.2f}ms | \"\n",
        "                                  f\"Job overall: {job_time:.3f}s\")\n",
        "                    # =========================================================\n",
        "\n",
        "                    counts = result.get_counts()\n",
        "\n",
        "                    if isinstance(counts, list): counts = counts[0]\n",
        "\n",
        "                    # 4. Calculate Expectation\n",
        "                    shots = sum(counts.values())\n",
        "                    count_0 = 0\n",
        "                    for bitstring, count in counts.items():\n",
        "                        if bitstring[-1] == '0':\n",
        "                            count_0 += count\n",
        "\n",
        "                    p0 = count_0 / shots\n",
        "                    p1 = 1 - p0\n",
        "                    pub_expectations.append(p0 - p1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Job failed: {e}\")\n",
        "                    pub_expectations.append(0.0)\n",
        "\n",
        "            data = DataBin(evs=np.array(pub_expectations), shape=(len(pub_expectations),))\n",
        "            job_results.append(PubResult(data=data))\n",
        "\n",
        "        return SimpleIQMJob(PrimitiveResult(job_results))\n",
        "\n",
        "    def print_timing_summary(self):\n",
        "        \"\"\"Detailed summary.\"\"\"\n",
        "        if not self.timestamp_history:\n",
        "            print(\"No data about timestampach.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"DETAILED SUMMARY OF THE TIMESTAMPS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Number of executed jobs: {len(self.timestamp_history)}\")\n",
        "\n",
        "        qpu_times = []\n",
        "        compile_times = []\n",
        "        queue_times = []\n",
        "        network_times = []\n",
        "\n",
        "        for t in self.timestamp_history:\n",
        "            ts = t['raw_timestamps']\n",
        "\n",
        "            # QPU\n",
        "            if ts.get('execution_started') and ts.get('execution_ended'):\n",
        "                qpu_times.append((ts['execution_ended'] - ts['execution_started']).total_seconds())\n",
        "\n",
        "            # Compilation\n",
        "            if ts.get('compilation_started') and ts.get('compilation_ended'):\n",
        "                compile_times.append((ts['compilation_ended'] - ts['compilation_started']).total_seconds())\n",
        "\n",
        "            # Queue (waiting for QPU)\n",
        "            if ts.get('pending_execution') and ts.get('execution_started'):\n",
        "                queue_times.append((ts['execution_started'] - ts['pending_execution']).total_seconds())\n",
        "\n",
        "            # (created->received + ready->completed)\n",
        "            net_time = 0\n",
        "            if ts.get('created') and ts.get('received'):\n",
        "                net_time += (ts['received'] - ts['created']).total_seconds()\n",
        "            if ts.get('ready') and ts.get('completed'):\n",
        "                net_time += (ts['completed'] - ts['ready']).total_seconds()\n",
        "            network_times.append(net_time)\n",
        "\n",
        "        print(f\"\\nTIME ON QPU :     {sum(qpu_times)*1000:8.2f} ms  (mean: {np.mean(qpu_times)*1000:.2f} ms/job)\")\n",
        "        print(f\"Compilation :           {sum(compile_times)*1000:8.2f} ms  (mean: {np.mean(compile_times)*1000:.2f} ms/job)\")\n",
        "        print(f\"Queue (wait QPU) :   {sum(queue_times)*1000:8.2f} ms  (mean: {np.mean(queue_times)*1000:.2f} ms/job)\")\n",
        "        print(f\"(upload+down) :   {sum(network_times)*1000:8.2f} ms  (mean: {np.mean(network_times)*1000:.2f} ms/job)\")\n",
        "\n",
        "        total_measured = sum(qpu_times) + sum(compile_times) + sum(queue_times) + sum(network_times)\n",
        "        total_job = sum(t['job_time_total'] for t in self.timestamp_history)\n",
        "        other = total_job - total_measured\n",
        "\n",
        "        print(f\"Others (validation etc): {other*1000:8.2f} ms\")\n",
        "        print(f\"\\nTIME OVERALL:       {total_job*1000:8.2f} ms ({total_job:.3f} s)\")\n",
        "\n",
        "        print(\"\\n\" + \"-\"*40)\n",
        "        print(\"PERCENTAGE DISTRIBUTION: \")\n",
        "        print(f\"  QPU:        {100*sum(qpu_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Compilation: {100*sum(compile_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Queue:    {100*sum(queue_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Network:       {100*sum(network_times)/total_job:5.1f}%\")\n",
        "        print(f\"  Others:       {100*other/total_job:5.1f}%\")\n",
        "        print(\"=\"*60 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "nZzZFnGIPPza"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, ansatz_circuit, num_qubits, backend=None):\n",
        "        super().__init__()\n",
        "        # 1. Initialize the feature map with 4 inputs but 5 qubits\n",
        "        self.feature_map = self.angle_encoding(num_qubits)\n",
        "\n",
        "        # 2. Combine feature map and ansatz\n",
        "        self.qc = QuantumCircuit(num_qubits)\n",
        "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
        "        self.qc.compose(ansatz_circuit, inplace=True)\n",
        "\n",
        "        input_params = list(self.feature_map.parameters)\n",
        "        weight_params = list(ansatz_circuit.parameters)\n",
        "\n",
        "        # 3. Define Observable (Z on the last qubit)\n",
        "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
        "\n",
        "        # 4. Choose Estimator (Hardware vs Simulation)\n",
        "        if backend:\n",
        "            # Using your custom IQM bridge\n",
        "            estimator = IQMBackendEstimator(backend, options={\"shots\": 1000})\n",
        "            gradient = None # ParamShift is too slow for real hardware training\n",
        "        else:\n",
        "            # Local simulation\n",
        "            estimator = StatevectorEstimator()\n",
        "            gradient = ParamShiftEstimatorGradient(estimator)\n",
        "\n",
        "        # 5. Build QNN\n",
        "        self.qnn = EstimatorQNN(\n",
        "            circuit=self.qc,\n",
        "            observables=observable,\n",
        "            input_params=input_params,\n",
        "            weight_params=weight_params,\n",
        "            estimator=estimator,\n",
        "            gradient=gradient\n",
        "        )\n",
        "\n",
        "        self.quantum_layer = TorchConnector(self.qnn)\n",
        "\n",
        "    def angle_encoding(self, num_qubits):\n",
        "        # We have 4 features from the dataset\n",
        "        num_features = num_qubits  # Changed from 4 to num_qubits to match input data dimensions\n",
        "        qc_data = QuantumCircuit(num_qubits)\n",
        "\n",
        "        # We create exactly num_features parameters to match X_batch size\n",
        "        input_params = ParameterVector('x', num_features)\n",
        "\n",
        "        for i in range(num_features):\n",
        "            # Map features to the first num_features qubits\n",
        "            qc_data.ry(input_params[i], i)\n",
        "\n",
        "        return qc_data\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.quantum_layer(x)"
      ],
      "metadata": {
        "id": "sMmIjRrUPR5e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.005\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "print(\"Loading data...\")'''\n",
        "\n",
        "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
        "\n",
        "y_train = 2 * y_train_raw - 1\n",
        "y_test = 2 * y_test_raw - 1\n",
        "\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "print(f\"Data ready. Number of training samples: {len(X_train)}\")"
      ],
      "metadata": {
        "id": "c6a8_lSrPTxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01c0c1b-ee1b-4d07-92eb-cd4afe569f27"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ready. Number of training samples: 1097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preparing the DataLoader ---\n",
        "\n",
        "# Data conversion to tensors for PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "'''# Creating a dataset with X_train_tensor and Y_train_tensor\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "\n",
        "# Creating a DataLoader, which now automatically handles shuffle in the training loop\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)'''\n",
        "\n"
      ],
      "metadata": {
        "id": "nL5hvBeEPVb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c8452093-5702-4d6c-8d4c-ddc1c5555ebd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Creating a dataset with X_train_tensor and Y_train_tensor\\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\\n\\n# Creating a DataLoader, which now automatically handles shuffle in the training loop\\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.MSELoss()\n",
        "\n",
        "# Inicializing the model\n",
        "final_ansatz = ansatz_Odra(5, 6)\n",
        "model = HybridModel(final_ansatz, 5)\n",
        "\n",
        "model.load_state_dict(torch.load(\"odra_ansatz_weights.pth\"))\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ… Weights loaded successfully. Starting evaluation...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "\n",
        "    predicted = (test_outputs > 0).float() * 2 - 1\n",
        "    correct = (predicted == y_test_tensor).sum().item()\n",
        "    test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "print(f\"--- RESULTS FOR LOADED WEIGHTS ---\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "'''\n",
        "\n",
        "# Initializing the ADAM optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Starting training... Epochs: {EPOCHS}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batches_count = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()           # Reset gradients\n",
        "        output = model(X_batch)         # Forward\n",
        "        loss = loss_function(output, y_batch) # Loss\n",
        "        loss.backward()                 # Backward\n",
        "        optimizer.step()                # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batches_count += 1\n",
        "\n",
        "    # Evaluation on tensors\n",
        "    with torch.no_grad(): # To test our model we turn off the gradients\n",
        "\n",
        "        test_outputs = model(X_test_tensor)\n",
        "        test_loss = loss_function(test_outputs, y_test_tensor).item()\n",
        "\n",
        "        # Calculating accuracy:\n",
        "        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\n",
        "        # Then, multiply it by two, so for True = 2.0 False = 0.0\n",
        "        # Substract 1 and the labels are either 1.0 or -1.0\n",
        "        predicted = (test_outputs > 0).float() * 2 - 1\n",
        "        correct = (predicted == y_test_tensor).sum().item()\n",
        "        test_accuracy = correct / len(y_test_tensor)\n",
        "\n",
        "    avg_loss = epoch_loss / batches_count\n",
        "    train_loss_history.append(avg_loss)\n",
        "    test_loss_history.append(test_loss)\n",
        "    acc_history.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"quantum_star_weights.pth\")\n",
        "print(f\"âœ… Wagi zapisane do pliku: quantum_star_weights.pth\")\n",
        "'''"
      ],
      "metadata": {
        "id": "oHEfEhwfPXto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "43bea810-e053-450c-ce41-7186c1e9e8d6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Weights loaded successfully. Starting evaluation...\n",
            "--- RESULTS FOR LOADED WEIGHTS ---\n",
            "Test Accuracy: 0.9055\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Initializing the ADAM optimizer\\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\\n\\nprint(f\"Starting training... Epochs: {EPOCHS}\")\\n\\nfor epoch in range(EPOCHS):\\n    model.train()\\n    epoch_loss = 0.0\\n    batches_count = 0\\n\\n    for X_batch, y_batch in train_loader:\\n\\n        optimizer.zero_grad()           # Reset gradients\\n        output = model(X_batch)         # Forward\\n        loss = loss_function(output, y_batch) # Loss\\n        loss.backward()                 # Backward\\n        optimizer.step()                # Update weights\\n\\n        epoch_loss += loss.item()\\n        batches_count += 1\\n\\n    # Evaluation on tensors\\n    with torch.no_grad(): # To test our model we turn off the gradients\\n\\n        test_outputs = model(X_test_tensor)\\n        test_loss = loss_function(test_outputs, y_test_tensor).item()\\n\\n        # Calculating accuracy:\\n        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\\n        # Then, multiply it by two, so for True = 2.0 False = 0.0\\n        # Substract 1 and the labels are either 1.0 or -1.0\\n        predicted = (test_outputs > 0).float() * 2 - 1\\n        correct = (predicted == y_test_tensor).sum().item()\\n        test_accuracy = correct / len(y_test_tensor)\\n\\n    avg_loss = epoch_loss / batches_count\\n    train_loss_history.append(avg_loss)\\n    test_loss_history.append(test_loss)\\n    acc_history.append(test_accuracy)\\n\\n    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")\\n\\ntorch.save(model.state_dict(), \"quantum_star_weights.pth\")\\nprint(f\"âœ… Wagi zapisane do pliku: quantum_star_weights.pth\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_outputs_tensor = model(X_test_tensor)\n",
        "    test_outputs = test_outputs_tensor.numpy()\n",
        "\n",
        "predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
        "\n",
        "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
        "c_matrix_display.plot()\n",
        "\n",
        "#epochs = range(1, len(train_loss_history) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "'''\n",
        "# Plot 1: Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
        "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
        "plt.title('IQM Spark adapted anzatz Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))\n",
        "'''"
      ],
      "metadata": {
        "id": "LudXImudPcir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "fa15a97e-c2d5-4ce4-8486-28aeffbd1f82"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Plot 1: Loss\\nplt.subplot(1, 2, 1)\\nplt.plot(epochs, train_loss_history, label=\\'Train Loss\\', color=\\'blue\\')\\nplt.plot(epochs, test_loss_history, label=\\'Test Loss\\', color=\\'red\\', linestyle=\\'--\\')\\nplt.title(\\'Loss Over Epochs\\')\\nplt.xlabel(\\'Epochs\\')\\nplt.ylabel(\\'Loss\\')\\nplt.legend()\\nplt.grid(True)\\n\\n# Plot 2: Accuracy\\nplt.subplot(1, 2, 2)\\nplt.plot(epochs, acc_history, label=\\'Test Accuracy\\', color=\\'green\\')\\nplt.title(\\'IQM Spark adapted anzatz Accuracy Over Epochs\\')\\nplt.xlabel(\\'Epochs\\')\\nplt.ylabel(\\'Accuracy\\')\\nplt.legend()\\nplt.grid(True)\\n\\nplt.show()\\n\\nprint(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Connect to IQM\n",
        "# ---------------------------------------------------------\n",
        "try:\n",
        "    # Replace URL/Token as needed\n",
        "    provider = IQMProvider(\"https://odra5.e-science.pl/\", token=input(\"Enter IQM Token: \"))\n",
        "    iqm_backend = provider.get_backend()\n",
        "    print(f\"Connected to backend: {iqm_backend.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Connection error: {e}\")\n",
        "    # Stop execution if connection fails (optional safety)\n",
        "    exit()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Instantiate the Bridge & QNN\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Create the hardware estimator\n",
        "SHOTS = 100\n",
        "hardware_estimator = IQMBackendEstimator(iqm_backend, options={\"shots\": SHOTS})\n",
        "\n",
        "print(\"Building Hardware QNN for 5 Qubits...\")\n",
        "\n",
        "# CONFIGURATION\n",
        "N_QUBITS = 5\n",
        "DEPTH = 6  # Must be divisible by 2 based on the ansatz logic\n",
        "\n",
        "# Build Circuit Components\n",
        "hw_ansatz = ansatz_Odra(N_QUBITS, DEPTH)\n",
        "\n",
        "hw_feature_map = model.angle_encoding(N_QUBITS)\n",
        "\n",
        "hw_qc = QuantumCircuit(N_QUBITS)\n",
        "hw_qc.compose(hw_feature_map, qubits=range(N_QUBITS), inplace=True)\n",
        "hw_qc.compose(hw_ansatz, inplace=True)\n",
        "\n",
        "# Observable for 5 Qubits\n",
        "# \"IIIIZ\" measures Qubit 0 (Qiskit is little-endian: q4, q3, q2, q1, q0)\n",
        "observable = SparsePauliOp.from_list([(\"I\" * (N_QUBITS - 1) + \"Z\", 1)])\n",
        "\n",
        "# Create QNN with the HARDWARE ESTIMATOR\n",
        "hw_qnn = EstimatorQNN(\n",
        "    circuit=hw_qc,\n",
        "    observables=observable,\n",
        "    input_params=list(hw_feature_map.parameters),\n",
        "    weight_params=list(hw_ansatz.parameters),\n",
        "    estimator=hardware_estimator\n",
        ")\n",
        "\n",
        "# Create Torch Layer\n",
        "iqm_model = TorchConnector(hw_qnn)\n",
        "\n",
        "# LOAD TRAINED WEIGHTS\n",
        "# ---------------------------------------------------------\n",
        "print(\"Loading weights from file...\")\n",
        "file_path = \"odra_ansatz_weights.pth\"\n",
        "\n",
        "try:\n",
        "    state_dict = torch.load(file_path)\n",
        "\n",
        "    if \"weight\" in state_dict:\n",
        "        iqm_model.load_state_dict(state_dict)\n",
        "    elif \"quantum_layer.weight\" in state_dict:\n",
        "        with torch.no_grad():\n",
        "            iqm_model.weight.copy_(state_dict[\"quantum_layer.weight\"])\n",
        "    else:\n",
        "        iqm_model.load_state_dict(state_dict)\n",
        "\n",
        "    print(f\"âœ… Weights from {file_path} loaded successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n[!] Error: {e}\""
      ],
      "metadata": {
        "id": "f2put-w7PfGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_circuit_stats(circuit, backend):\n",
        "    # Transpile to see how the hardware actually executes it\n",
        "    t_qc = transpile(circuit, backend, optimization_level=3)\n",
        "    ops = t_qc.count_ops()\n",
        "    return {\n",
        "        'Depth': t_qc.depth(),\n",
        "        'SWAPs': ops.get('swap', 0),\n",
        "        'CNOTs/CZs': ops.get('cz', 0) + ops.get('cx', 0)\n",
        "    }\n",
        "\n",
        "qnn_circuit = iqm_model.neural_network.circuit\n",
        "stats = get_circuit_stats(qnn_circuit, iqm_backend)\n",
        "\n",
        "#Select sample\n",
        "sample_idx = 67\n",
        "sample_input = X_test_tensor[sample_idx]\n",
        "actual_label = y_test_tensor[sample_idx].item()\n",
        "\n",
        "print(f\"Sending job to IQM Spark...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = iqm_model(sample_input)\n",
        "\n",
        "predicted_label = 1 if prediction.item() > 0 else -1\n",
        "\n",
        "# --- FINAL COMPARISON TABLE ---\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(f\"        HARDWARE PERFORMANCE REPORT\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Circuit Depth:      {stats['Depth']}\")\n",
        "print(f\"SWAP Gates:         {stats['SWAPs']}  <-- (Target: 0)\")\n",
        "print(f\"CZ Gates:           {stats['CNOTs/CZs']}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"IQM Raw Output:     {prediction.item():.4f}\")\n",
        "print(f\"Predicted Class:    {predicted_label}\")\n",
        "print(f\"Actual Class:       {int(actual_label)}\")\n",
        "print(f\"Confidence Level:   {abs(prediction.item()):.2%}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "JV8MKJx1PhD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n"
      ],
      "metadata": {
        "id": "HtwHsrPYuHFP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.12 (Qiskit)",
      "language": "python",
      "name": "qiskit_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}