{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup & Configuration\n",
    "\n",
    "## SSL Certificate Fix (macOS)\n",
    "Run this cell first if you encounter SSL errors when installing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ReVDTmxqlXfC",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "f52b4ad6-6cb6-4743-91b5-52d48b1f877a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSL cert location: /opt/homebrew/etc/openssl@3/cert.pem\n",
      "Found existing installation: qiskit 2.1.2\n",
      "Uninstalling qiskit-2.1.2:\n",
      "  Successfully uninstalled qiskit-2.1.2\n",
      "\u001b[33mWARNING: Skipping qiskit-iqm as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: iqm-client 33.0.4\n",
      "Uninstalling iqm-client-33.0.4:\n",
      "  Successfully uninstalled iqm-client-33.0.4\n",
      "Found existing installation: qiskit-machine-learning 0.9.0\n",
      "Uninstalling qiskit-machine-learning-0.9.0:\n",
      "  Successfully uninstalled qiskit-machine-learning-0.9.0\n",
      "Found existing installation: qiskit-aer 0.17.2\n",
      "Uninstalling qiskit-aer-0.17.2:\n",
      "  Successfully uninstalled qiskit-aer-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting qiskit<3.0,>=2.0\n",
      "  Using cached qiskit-2.3.0-cp310-abi3-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting qiskit-aer>=0.15.0\n",
      "  Using cached qiskit_aer-0.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.3 kB)\n",
      "Collecting qiskit-machine-learning<0.10,>=0.9\n",
      "  Using cached qiskit_machine_learning-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting iqm-client<34.0,>=33.0 (from iqm-client[qiskit]<34.0,>=33.0)\n",
      "  Using cached iqm_client-33.0.4-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in ./.venv/lib/python3.12/site-packages (from qiskit<3.0,>=2.0) (0.17.1)\n",
      "Requirement already satisfied: numpy<3,>=1.17 in ./.venv/lib/python3.12/site-packages (from qiskit<3.0,>=2.0) (2.4.2)\n",
      "Requirement already satisfied: scipy>=1.5 in ./.venv/lib/python3.12/site-packages (from qiskit<3.0,>=2.0) (1.15.3)\n",
      "Requirement already satisfied: dill>=0.3 in ./.venv/lib/python3.12/site-packages (from qiskit<3.0,>=2.0) (0.4.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in ./.venv/lib/python3.12/site-packages (from qiskit<3.0,>=2.0) (5.6.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from qiskit<3.0,>=2.0) (4.15.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in ./.venv/lib/python3.12/site-packages (from qiskit-machine-learning<0.10,>=0.9) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=40.1 in ./.venv/lib/python3.12/site-packages (from qiskit-machine-learning<0.10,>=0.9) (82.0.0)\n",
      "Requirement already satisfied: packaging==24.1 in ./.venv/lib/python3.12/site-packages (from iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.9.2 in ./.venv/lib/python3.12/site-packages (from iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.12.5)\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.12/site-packages (from iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.32.3)\n",
      "Requirement already satisfied: iqm-pulse<13,>=12.7.4 in ./.venv/lib/python3.12/site-packages (from iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (12.7.4)\n",
      "Requirement already satisfied: iqm-station-control-client<13,>=12.0.4 in ./.venv/lib/python3.12/site-packages (from iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (12.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2026.1.4)\n",
      "Collecting qiskit<3.0,>=2.0\n",
      "  Using cached qiskit-2.1.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5 in ./.venv/lib/python3.12/site-packages (from qiskit-aer>=0.15.0) (7.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in ./.venv/lib/python3.12/site-packages (from qiskit-aer>=0.15.0) (2.9.0.post0)\n",
      "Requirement already satisfied: iqm-data-definitions<3.0,>=2.18 in ./.venv/lib/python3.12/site-packages (from iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.22)\n",
      "Requirement already satisfied: python-rapidjson==1.20 in ./.venv/lib/python3.12/site-packages (from iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.20)\n",
      "Requirement already satisfied: jinja2==3.0.3 in ./.venv/lib/python3.12/site-packages (from iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (3.0.3)\n",
      "Requirement already satisfied: scipy-stubs in ./.venv/lib/python3.12/site-packages (from iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.17.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2==3.0.3->iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (3.0.3)\n",
      "Requirement already satisfied: protobuf<5.0,>=4.25.3 in ./.venv/lib/python3.12/site-packages (from iqm-data-definitions<3.0,>=2.18->iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (4.25.8)\n",
      "Requirement already satisfied: types-protobuf in ./.venv/lib/python3.12/site-packages (from iqm-data-definitions<3.0,>=2.18->iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (6.32.1.20251210)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp<2.0,>=1.25.0 in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.65.4 in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.78.0)\n",
      "Requirement already satisfied: PyYAML<7.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (6.0.3)\n",
      "Requirement already satisfied: types-requests in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.32.4.20260107)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (4.67.3)\n",
      "Requirement already satisfied: types-tqdm in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (4.67.3.20260205)\n",
      "Requirement already satisfied: iqm-exa-common<28,>=27.4.4 in ./.venv/lib/python3.12/site-packages (from iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (27.4.4)\n",
      "Requirement already satisfied: python-dotenv==0.21.1 in ./.venv/lib/python3.12/site-packages (from iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.21.1)\n",
      "Requirement already satisfied: xarray==2024.10.0 in ./.venv/lib/python3.12/site-packages (from iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2024.10.0)\n",
      "Requirement already satisfied: ruamel-yaml==0.17.32 in ./.venv/lib/python3.12/site-packages (from iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.17.32)\n",
      "Requirement already satisfied: ruamel-yaml-clib==0.2.8 in ./.venv/lib/python3.12/site-packages (from iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.2.8)\n",
      "Requirement already satisfied: six==1.16.0 in ./.venv/lib/python3.12/site-packages (from iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.16.0)\n",
      "Requirement already satisfied: types-six in ./.venv/lib/python3.12/site-packages (from iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.17.0.20251009)\n",
      "Requirement already satisfied: pandas>=2.1 in ./.venv/lib/python3.12/site-packages (from xarray==2024.10.0->iqm-exa-common<28,>=27.4.4->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (3.0.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.27.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.27.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.3.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.15 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.27.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (1.27.0)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (8.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk~=1.27.0->opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.48b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0,>=2.9.2->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0,>=2.9.2->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0,>=2.9.2->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.4.2)\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in ./.venv/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp<2.0,>=1.25.0->iqm-station-control-client<13,>=12.0.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (2.1.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.2->qiskit-machine-learning<0.10,>=0.9) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.2->qiskit-machine-learning<0.10,>=0.9) (3.6.0)\n",
      "Requirement already satisfied: optype<0.16,>=0.14.0 in ./.venv/lib/python3.12/site-packages (from optype[numpy]<0.16,>=0.14.0->scipy-stubs->iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (0.15.0)\n",
      "Requirement already satisfied: numpy-typing-compat<20251207,>=20250818.1.25 in ./.venv/lib/python3.12/site-packages (from optype[numpy]<0.16,>=0.14.0->scipy-stubs->iqm-pulse<13,>=12.7.4->iqm-client<34.0,>=33.0->iqm-client[qiskit]<34.0,>=33.0) (20251206.2.4)\n",
      "Using cached qiskit_machine_learning-0.9.0-py3-none-any.whl (263 kB)\n",
      "Using cached iqm_client-33.0.4-py3-none-any.whl (148 kB)\n",
      "Using cached qiskit-2.1.2-cp39-abi3-macosx_11_0_arm64.whl (6.8 MB)\n",
      "Using cached qiskit_aer-0.17.2-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Installing collected packages: qiskit, qiskit-machine-learning, qiskit-aer, iqm-client\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/4\u001b[0m [iqm-client]\u001b[0m \u001b[32m2/4\u001b[0m [qiskit-aer]\n",
      "\u001b[1A\u001b[2KSuccessfully installed iqm-client-33.0.4 qiskit-2.1.2 qiskit-aer-0.17.2 qiskit-machine-learning-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/jkw/Documents/uni/axion/QC1/.venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Installation complete.\n"
     ]
    }
   ],
   "source": [
    "# SSL CERTIFICATE FIX (macOS)\n",
    "# If you see SSL errors, run this first:\n",
    "import subprocess\n",
    "import sys\n",
    "import ssl\n",
    "try:\n",
    "    # Try to fix SSL certificates on macOS\n",
    "    cert_path = ssl.get_default_verify_paths().openssl_cafile\n",
    "    print(f\"SSL cert location: {cert_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"SSL check: {e}\")\n",
    "\n",
    "# 1. Uninstall the conflicting/deprecated versions first\n",
    "%pip uninstall -y qiskit qiskit-iqm iqm-client qiskit-machine-learning qiskit-aer\n",
    "\n",
    "# 2. Install the 2026-supported stack:\n",
    "#    - qiskit 2.x (latest stable)\n",
    "\n",
    "#    - qiskit-aer 0.15.x (Qiskit 2.x compatible simulator)\n",
    "#    - qiskit-machine-learning 0.9.x (Qiskit 2.0 compatibility release)\n",
    "#    - iqm-client[qiskit] 33.x (includes built-in Qiskit adapter, replaces deprecated qiskit-iqm)\n",
    "# Note: --trusted-host flags bypass SSL verification as a workaround\n",
    "%pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org \\\n",
    "             \"qiskit>=2.0,<3.0\" \\\n",
    "             \"qiskit-aer>=0.15.0\" \\\n",
    "             \"qiskit-machine-learning>=0.9,<0.10\" \\\n",
    "             \"iqm-client[qiskit]>=33.0,<34.0\"\n",
    "\n",
    "print(\"‚úÖ Installation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports\n",
    "All necessary libraries for quantum computing, machine learning, and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKSJGRyG0ouM",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# IQM & Qiskit imports\n",
    "from iqm.qiskit_iqm import IQMProvider\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.primitives import StatevectorEstimator, PrimitiveResult, PubResult\n",
    "from qiskit.primitives.base import BaseEstimatorV2\n",
    "from qiskit.primitives.containers.data_bin import DataBin\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# Qiskit Machine Learning\n",
    "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data science & ML\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilities\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Circuit Definitions\n",
    "\n",
    "## Hardware-Efficient Ansatz\n",
    "Custom quantum circuit designed for IQM's star topology (5 qubits, QB3 as central hub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pz4kqrFfANdX",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ansatz(n_qubits, depth):\n",
    "    \"\"\"\n",
    "    Constructs a hardware-efficient ansatz tailored for a star topology.\n",
    "    QB3 (index 2) acts as the central hub for entanglement to avoid SWAP gates.\n",
    "    Native CZ gates are used to minimize decomposition errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Each full iteration (2 layers) consumes:\n",
    "    # Layer 1: n_qubits (RY) + 4 (RZ before CZ) = 9 parameters\n",
    "    # Layer 2: n_qubits (RX) + 4 (RY before CZ) = 9 parameters\n",
    "    # Total = 18 parameters per iteration (where depth // 2 is the number of iterations)\n",
    "    params_per_iter = 18\n",
    "    total_params = params_per_iter * (depth // 2)\n",
    "    theta = ParameterVector('Œ∏', total_params)\n",
    "\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    # The loop iterates (depth // 2) times to execute two-layer blocks.\n",
    "    for j in range(depth // 2):\n",
    "        offset = j * params_per_iter\n",
    "\n",
    "        # -------- Layer 1: RY + Star CZ (RZ-based) --------\n",
    "\n",
    "        # Sub-layer: Independent RY rotations on all qubits\n",
    "        for i in range(n_qubits):\n",
    "            qc.ry(theta[offset + i], i)\n",
    "\n",
    "        # Sub-layer: Entanglement using Star Topology\n",
    "        # QB3 (index 2) is the central qubit. We connect it to [0, 1, 3, 4].\n",
    "        # RZ rotations are added to maintain expressibility while using native CZ.\n",
    "        target_qubits = [0, 1, 3, 4]\n",
    "        for idx, target in enumerate(target_qubits):\n",
    "            # Using parameters offset+5 to offset+8\n",
    "            qc.rz(theta[offset + n_qubits + idx], target)\n",
    "            qc.cz(2, target)\n",
    "\n",
    "        # -------- Layer 2: RX + Star CZ (RY-based) --------\n",
    "\n",
    "        # Move the offset forward for the second layer within the same iteration\n",
    "        offset_layer2 = offset + 9\n",
    "\n",
    "        # Sub-layer: Independent RX rotations on all qubits\n",
    "        for i in range(n_qubits):\n",
    "            qc.rx(theta[offset_layer2 + i], i)\n",
    "\n",
    "        # Sub-layer: Entanglement using Star Topology\n",
    "        # RY rotations are used here to simulate the effect of a CRY-like interaction.\n",
    "        for idx, target in enumerate(target_qubits):\n",
    "            # Using parameters offset_layer2+5 to offset_layer2+8\n",
    "            qc.ry(theta[offset_layer2 + n_qubits + idx], target)\n",
    "            qc.cz(2, target)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQM Backend Estimator\n",
    "Custom estimator class that interfaces with IQM quantum hardware and tracks detailed timing information.\n",
    "\n",
    "<details>\n",
    "<summary>üìä Timing Metrics Captured</summary>\n",
    "\n",
    "- **QPU Execution Time**: Actual quantum circuit execution\n",
    "- **Compilation Time**: Circuit transpilation and optimization  \n",
    "- **Queue Time**: Waiting for QPU availability\n",
    "- **Network Time**: Job upload and result download\n",
    "- **Total Job Time**: End-to-end execution\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZG6u0H3XgA_",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class SimpleIQMJob:\n",
    "    \"\"\"A dummy job that simply holds the result.\"\"\"\n",
    "    def __init__(self, result):\n",
    "        self._result = result\n",
    "    \n",
    "    def result(self):\n",
    "        return self._result\n",
    "\n",
    "# --- THE BRIDGE CLASS ---\n",
    "class IQMBackendEstimator(BaseEstimatorV2):\n",
    "    def __init__(self, backend, options=None):\n",
    "        super().__init__()\n",
    "        self._backend = backend\n",
    "        self._options = options or {\"shots\": 100}\n",
    "        # collecting timestamps\n",
    "        self.timestamp_history = []\n",
    "        self.total_qpu_time = 0.0  # Sum of time on quantum\n",
    "\n",
    "    def _extract_timestamps(self, result):\n",
    "        try:\n",
    "            timeline = result._metadata.get('timeline', [])\n",
    "            if not timeline:\n",
    "                return None\n",
    "            \n",
    "            timestamps = {}\n",
    "            for entry in timeline:\n",
    "                timestamps[entry.status] = entry.timestamp\n",
    "            \n",
    "            return timestamps\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def run(self, pubs, precision=None):\n",
    "        if not isinstance(pubs, list): pubs = [pubs]\n",
    "        job_results = []\n",
    "        \n",
    "        # 1. Prepare Circuit\n",
    "        base_circuit = pubs[0][0]\n",
    "        circuit_with_meas = base_circuit.copy()\n",
    "        if circuit_with_meas.num_clbits == 0:\n",
    "            circuit_with_meas.measure_all()\n",
    "        \n",
    "        # 2. Transpile\n",
    "        transpiled_qc = transpile(circuit_with_meas, self._backend, optimization_level=3)\n",
    "        \n",
    "        for pub in pubs:\n",
    "            _, observables, parameter_values = pub\n",
    "            if parameter_values.ndim == 1:\n",
    "                parameter_values = [parameter_values]\n",
    "            \n",
    "            pub_expectations = []\n",
    "            \n",
    "            for params in parameter_values:\n",
    "                bound_qc = transpiled_qc.assign_parameters(params)\n",
    "                \n",
    "                # 3. Execute on Hardware\n",
    "                try:\n",
    "                    job = self._backend.run(bound_qc, shots=self._options[\"shots\"])\n",
    "                    result = job.result()\n",
    "                    \n",
    "                    # ========== TIMESTAMPS (IQM timeline) ==========\n",
    "                    ts = self._extract_timestamps(result)\n",
    "                    if ts:\n",
    "                        exec_start = ts.get('execution_started')\n",
    "                        exec_end = ts.get('execution_ended')\n",
    "                        comp_start = ts.get('compilation_started')\n",
    "                        comp_end = ts.get('compilation_ended')\n",
    "                        job_created = ts.get('created')\n",
    "                        job_completed = ts.get('completed')\n",
    "                        \n",
    "                        if exec_start and exec_end:\n",
    "                            execution_time = (exec_end - exec_start).total_seconds()\n",
    "                            compile_time = (comp_end - comp_start).total_seconds() if comp_start and comp_end else 0\n",
    "                            job_time = (job_completed - job_created).total_seconds() if job_created and job_completed else 0\n",
    "                            \n",
    "                            self.timestamp_history.append({\n",
    "                                'execution_time_qpu': execution_time,\n",
    "                                'job_time_total': job_time,\n",
    "                                'compile_time': compile_time,\n",
    "                                'raw_timestamps': ts\n",
    "                            })\n",
    "                            self.total_qpu_time += execution_time\n",
    "                            \n",
    "                            print(f\"TIME ON QPU: {execution_time*1000:.2f}ms | \"\n",
    "                                  f\"Compilation: {compile_time*1000:.2f}ms | \"\n",
    "                                  f\"Job overall: {job_time:.3f}s\")\n",
    "                    # =========================================================\n",
    "                    \n",
    "                    counts = result.get_counts()\n",
    "                    \n",
    "                    if isinstance(counts, list): counts = counts[0]\n",
    "\n",
    "                    # 4. Calculate Expectation\n",
    "                    shots = sum(counts.values())\n",
    "                    count_0 = 0\n",
    "                    for bitstring, count in counts.items():\n",
    "                        if bitstring[-1] == '0':\n",
    "                            count_0 += count\n",
    "                    \n",
    "                    p0 = count_0 / shots\n",
    "                    p1 = 1 - p0\n",
    "                    pub_expectations.append(p0 - p1)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Job failed: {e}\")\n",
    "                    pub_expectations.append(0.0)\n",
    "            \n",
    "            data = DataBin(evs=np.array(pub_expectations), shape=(len(pub_expectations),))\n",
    "            job_results.append(PubResult(data=data))\n",
    "\n",
    "        return SimpleIQMJob(PrimitiveResult(job_results))\n",
    "    \n",
    "    def print_timing_summary(self):\n",
    "        \"\"\"Detailed summary.\"\"\"\n",
    "        if not self.timestamp_history:\n",
    "            print(\"Brak danych o timestampach.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DETAILED SUMMARY OF THE TIMESTAMPS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Number of executed jobs: {len(self.timestamp_history)}\")\n",
    "        \n",
    "        qpu_times = []\n",
    "        compile_times = []\n",
    "        queue_times = []\n",
    "        network_times = []\n",
    "        \n",
    "        for t in self.timestamp_history:\n",
    "            ts = t['raw_timestamps']\n",
    "            \n",
    "            # QPU\n",
    "            if ts.get('execution_started') and ts.get('execution_ended'):\n",
    "                qpu_times.append((ts['execution_ended'] - ts['execution_started']).total_seconds())\n",
    "            \n",
    "            # Compilation\n",
    "            if ts.get('compilation_started') and ts.get('compilation_ended'):\n",
    "                compile_times.append((ts['compilation_ended'] - ts['compilation_started']).total_seconds())\n",
    "            \n",
    "            # Queue (waiting for QPU)\n",
    "            if ts.get('pending_execution') and ts.get('execution_started'):\n",
    "                queue_times.append((ts['execution_started'] - ts['pending_execution']).total_seconds())\n",
    "            \n",
    "            # (created->received + ready->completed)\n",
    "            net_time = 0\n",
    "            if ts.get('created') and ts.get('received'):\n",
    "                net_time += (ts['received'] - ts['created']).total_seconds()\n",
    "            if ts.get('ready') and ts.get('completed'):\n",
    "                net_time += (ts['completed'] - ts['ready']).total_seconds()\n",
    "            network_times.append(net_time)\n",
    "        \n",
    "        print(f\"\\nTIME ON QPU :     {sum(qpu_times)*1000:8.2f} ms  (mean: {np.mean(qpu_times)*1000:.2f} ms/job)\")\n",
    "        print(f\"Compilation :           {sum(compile_times)*1000:8.2f} ms  (mean: {np.mean(compile_times)*1000:.2f} ms/job)\")\n",
    "        print(f\"Queue (wait QPU) :   {sum(queue_times)*1000:8.2f} ms  (mean: {np.mean(queue_times)*1000:.2f} ms/job)\")\n",
    "        print(f\"(upload+down) :   {sum(network_times)*1000:8.2f} ms  (mean: {np.mean(network_times)*1000:.2f} ms/job)\")\n",
    "        \n",
    "        total_measured = sum(qpu_times) + sum(compile_times) + sum(queue_times) + sum(network_times)\n",
    "        total_job = sum(t['job_time_total'] for t in self.timestamp_history)\n",
    "        other = total_job - total_measured\n",
    "        \n",
    "        print(f\"Others (validation etc): {other*1000:8.2f} ms\")\n",
    "        print(f\"\\nTIME OVERALL:       {total_job*1000:8.2f} ms ({total_job:.3f} s)\")\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(\"PERCENTAGE DISTRIBUTION: \")\n",
    "        print(f\"  QPU:        {100*sum(qpu_times)/total_job:5.1f}%\")\n",
    "        print(f\"  Compilation: {100*sum(compile_times)/total_job:5.1f}%\")\n",
    "        print(f\"  Queue:    {100*sum(queue_times)/total_job:5.1f}%\")\n",
    "        print(f\"  Network:       {100*sum(network_times)/total_job:5.1f}%\")\n",
    "        print(f\"  Others:       {100*other/total_job:5.1f}%\")\n",
    "        print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Quantum-Classical Model\n",
    "PyTorch-based model that integrates quantum circuits with classical neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_JEkN9KJ-Fh",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The code below constructs the class HybridModel. It is built using the Qiskit and Pytorch library and\n",
    "    and utilizes its built-in tools, to create a model connecting classical and quantum computing.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, ansatz_circuit, num_qubits):\n",
    "        super().__init__()\n",
    "        self.feature_map = self.angle_encoding(num_qubits)\n",
    "\n",
    "        # Connecting the quantum circuit. Connecting our feature map (data) and ansatz\n",
    "        self.qc = QuantumCircuit(num_qubits)\n",
    "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
    "        self.qc.compose(ansatz_circuit, inplace=True)\n",
    "\n",
    "        # Firstly, we inicialize parameters. Our quantum model cannot tell whether the number came from ansatz or feature.\n",
    "        # That is why here we sort them into two lists. If the number came from feature_map, then it will be a feature and the other way around.\n",
    "        input_params = list(self.feature_map.parameters)\n",
    "        weight_params = list(ansatz_circuit.parameters)\n",
    "\n",
    "        '''\n",
    "        Measure the Z-operator (spin) on the very first qubit (q_0) and ignore all the other qubits.\n",
    "        Qiskit reads the string in a reversed order, that is why the Z gate is on the end.\n",
    "        SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)]) converts string into a mathematical matrix that Qiskit can use for calculations\n",
    "        Coefficient = 1 is a weight we multiply our result by. In QML it is mostly set to 1\n",
    "        '''\n",
    "\n",
    "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
    "\n",
    "        # Estimator takes ansatz, observables and parameters (data and weights), returns the Expectation value.\n",
    "        # !!!! CHANGE WHEN USING ON QUANTUM COMPUTER\n",
    "        # Needed when running quantum simulations, it should be changed when implementing on real quantum computer\n",
    "        estimator = StatevectorEstimator()\n",
    "\n",
    "        # Compute the gradients of the sampling probability by the Parameter Shift Rule.\n",
    "        gradient = ParamShiftEstimatorGradient(estimator)\n",
    "\n",
    "\n",
    "        '''\n",
    "        The EstimatorQNN\n",
    "        This class from Qiskit Machine Learning is used to instantiate the quantum neural network.\n",
    "        It leverages the Qiskit Primitives (Estimator) to efficiently calculate expectation values\n",
    "        of the quantum circuit. This allows the model to output continuous, differentiable values (gradients)\n",
    "        required for backpropagation in hybrid quantum-classical training.\n",
    "        '''\n",
    "\n",
    "        self.qnn = EstimatorQNN(\n",
    "            circuit=self.qc,\n",
    "            observables=observable,\n",
    "            input_params=input_params,\n",
    "            weight_params=weight_params,\n",
    "            estimator=estimator,\n",
    "            gradient=gradient\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        TORCH CONNECTOR\n",
    "        This line initializes the TorchConnector, which serves as a bridge between Qiskit and PyTorch. It wraps the Quantum Neural Network (QNN)\n",
    "        to make it function as a standard, differentiable PyTorch module (nn.Module).\n",
    "        This integration allows the quantum parameters to be optimized using standard PyTorch tools like\n",
    "        the Adam optimizer and automatic differentiation.\n",
    "        '''\n",
    "        self.quantum_layer = TorchConnector(self.qnn)\n",
    "\n",
    "        \"\"\"\n",
    "        Creates a Feature Map circuit using Angle Encoding. It maps classical input vectors\n",
    "        to the quantum space by applying Ry(theta) rotations on each qubit,\n",
    "        where the rotation angle theta corresponds to the input feature value.\n",
    "        This effectively encodes the data into the amplitudes of the quantum state\n",
    "        \"\"\"\n",
    "\n",
    "    def angle_encoding(self, num_qubits):\n",
    "        qc_data = QuantumCircuit(num_qubits)\n",
    "        input_params = ParameterVector('x', num_qubits)\n",
    "        for i in range(num_qubits):\n",
    "            qc_data.ry(input_params[i], i)\n",
    "        return qc_data\n",
    "\n",
    "    '''\n",
    "    This function acts as the main execution path. When the model receives data,\n",
    "    the forward function passes it into the quantum layer to be processed.\n",
    "    The quantum layer calculates the result based on the current circuit parameters and returns the prediction.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return self.quantum_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "# Utility Functions\n",
    "\n",
    "## Helper Functions for Evaluation\n",
    "\n",
    "<details>\n",
    "<summary>üîß Click to view helper function definitions</summary>\n",
    "\n",
    "The following helper functions simplify common operations:\n",
    "- **`connect_to_iqm_backend()`**: Manages IQM connection  \n",
    "- **`load_depth2_data()`**: Loads test data from CSV\n",
    "- **`load_depth2_weights()`**: Loads pretrained model weights\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# HELPER FUNCTIONS FOR EVALUATION\n",
    "# ========================================================\n",
    "# These functions simplify repeated operations:\n",
    "# - connect_to_iqm_backend(): IQM connection management\n",
    "# - load_depth2_data(): Load and cache test data\n",
    "# - load_depth2_weights(): Load pretrained weights with optional prefix stripping\n",
    "# ========================================================\n",
    "\n",
    "def connect_to_iqm_backend():\n",
    "    \"\"\"\n",
    "    Connects to IQM backend if not already connected.\n",
    "    Returns the backend instance.\n",
    "    \"\"\"\n",
    "    global iqm_backend\n",
    "\n",
    "    if 'iqm_backend' not in globals() or iqm_backend is None:\n",
    "        print(\"\\n‚ö†Ô∏è  IQM backend not found. Connecting...\")\n",
    "        try:\n",
    "            base_url = \"https://odra5.e-science.pl/\"\n",
    "            token = input(\"Enter IQM Token: \")\n",
    "\n",
    "            provider = IQMProvider(base_url, token=token)\n",
    "            iqm_backend = provider.get_backend()\n",
    "\n",
    "            print(f\"‚úì Connected to backend: {iqm_backend.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Connection error: {e}\")\n",
    "            raise RuntimeError(\"Failed to connect to IQM backend\") from e\n",
    "    else:\n",
    "        print(f\"‚úì Using existing IQM backend: {iqm_backend.name}\")\n",
    "\n",
    "        # Validate that the backend client can reach IQM JSON APIs.\n",
    "        # If the token is expired / wrong or the endpoint is redirecting to HTML,\n",
    "        # IQM client calls may return an HTML page instead of JSON.\n",
    "        try:\n",
    "            client = getattr(iqm_backend, \"client\", None)\n",
    "            server_client = getattr(client, \"_iqm_server_client\", None) if client is not None else None\n",
    "            headers = getattr(server_client, \"_default_headers\", None) if server_client is not None else None\n",
    "\n",
    "            auth_present = None\n",
    "            auth_len = None\n",
    "            if isinstance(headers, dict) and \"Authorization\" in headers and headers[\"Authorization\"] is not None:\n",
    "                auth_present = True\n",
    "                auth_len = len(str(headers[\"Authorization\"]))\n",
    "            elif isinstance(headers, dict):\n",
    "                auth_present = False\n",
    "\n",
    "            # Call may accept no args (default calset) depending on version.\n",
    "            try:\n",
    "                _ = client.get_dynamic_quantum_architecture()\n",
    "            except TypeError:\n",
    "                _ = client.get_dynamic_quantum_architecture(None)\n",
    "\n",
    "        except Exception:\n",
    "            # Force reconnect\n",
    "            iqm_backend = None\n",
    "            return connect_to_iqm_backend()\n",
    "\n",
    "    return iqm_backend\n",
    "\n",
    "\n",
    "def load_depth2_data():\n",
    "    \"\"\"\n",
    "    Loads depth2/testset.csv if not already loaded.\n",
    "    Returns (X_test, y_test) as numpy arrays.\n",
    "    \"\"\"\n",
    "    global X_test_depth2, y_test_depth2\n",
    "    \n",
    "    if 'X_test_depth2' not in globals():\n",
    "        try:\n",
    "            depth2_data = np.loadtxt(\"depth2/testset.csv\", delimiter=\",\")\n",
    "            \n",
    "            if depth2_data.shape[1] != 6:\n",
    "                raise ValueError(f\"Expected 6 columns, got {depth2_data.shape[1]}\")\n",
    "            \n",
    "            X_test_depth2 = depth2_data[:, :5].astype(np.float32)\n",
    "            y_test_depth2 = depth2_data[:, 5].astype(np.float32)\n",
    "            \n",
    "            print(f\"‚úì Loaded depth2 testset: {X_test_depth2.shape[0]} samples\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error loading testset: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(f\"‚úì Using existing depth2 testset: {X_test_depth2.shape[0]} samples\")\n",
    "    \n",
    "    return X_test_depth2, y_test_depth2\n",
    "\n",
    "\n",
    "def load_depth2_weights(model, strip_prefix=False):\n",
    "    \"\"\"\n",
    "    Loads weights from depth2/model_checkpoint_epoch_22.pth into model.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to load weights into\n",
    "        strip_prefix: If True, strips \"quantum_layer.\" prefix from keys\n",
    "                     (needed when loading HybridModel weights into TorchConnector)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        loaded_state = torch.load(\"depth2/model_checkpoint_epoch_22.pth\")\n",
    "        \n",
    "        if strip_prefix:\n",
    "            # Strip \"quantum_layer.\" prefix from keys\n",
    "            adjusted_state = {}\n",
    "            for key, value in loaded_state.items():\n",
    "                if key.startswith(\"quantum_layer.\"):\n",
    "                    new_key = key.replace(\"quantum_layer.\", \"\", 1)\n",
    "                    adjusted_state[new_key] = value\n",
    "                else:\n",
    "                    adjusted_state[key] = value\n",
    "            loaded_state = adjusted_state\n",
    "        \n",
    "        model.load_state_dict(loaded_state)\n",
    "        print(\"‚úì Loaded weights from depth2/model_checkpoint_epoch_22.pth\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error loading weights: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úì Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "# Model Setup\n",
    "\n",
    "## Initialize Quantum Model\n",
    "Create a 5-qubit model with depth-2 ansatz for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model with 5 qubits\n",
    "num_qubits = 5\n",
    "final_ansatz = ansatz(num_qubits, 2)\n",
    "model = HybridModel(final_ansatz, num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluation Experiments\n",
    "\n",
    "## Shot Count Comparison Analysis\n",
    "Compare model accuracy and performance across different shot counts on IQM hardware vs StatevectorEstimator baseline.\n",
    "\n",
    "**What this cell does:**\n",
    "1. Prompts for shot counts and sample size\n",
    "2. Evaluates baseline with StatevectorEstimator  \n",
    "3. Tests multiple shot configurations on IQM hardware\n",
    "4. Generates comparison graphs\n",
    "5. Displays results summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Shot Count Comparison Analysis\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SHOT COUNT COMPARISON ANALYSIS - IQM vs StatevectorEstimator\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "# Try regular tqdm first (works in most environments)\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    has_tqdm = True\n",
    "except ImportError:\n",
    "    has_tqdm = False\n",
    "    print(\"‚ö†Ô∏è  tqdm not installed. Install with: pip install tqdm\")\n",
    "    print(\"Continuing with simple progress output...\\n\")\n",
    "\n",
    "# ========================================================\n",
    "# A. Input Collection\n",
    "# ========================================================\n",
    "\n",
    "# Prompt for shot counts\n",
    "try:\n",
    "    shot_input = input(\"Enter shot counts (comma-separated, e.g., 10,50,100,500,1000): \")\n",
    "    shot_counts = [int(s.strip()) for s in shot_input.split(\",\")]\n",
    "    # Validate all shots are positive\n",
    "    if any(n <= 0 for n in shot_counts):\n",
    "        raise ValueError(\"All shot counts must be positive integers\")\n",
    "    # Sort for better visualization\n",
    "    shot_counts = sorted(shot_counts)\n",
    "    print(f\"‚úì Testing shot counts: {shot_counts}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"‚úó Invalid shot input: {e}\")\n",
    "    raise\n",
    "\n",
    "# Prompt for sample size\n",
    "try:\n",
    "    sample_input = input(f\"Enter number of samples to test (max 275): \")\n",
    "    n_samples = int(sample_input)\n",
    "    \n",
    "    if n_samples <= 0:\n",
    "        raise ValueError(\"Sample count must be positive\")\n",
    "    if n_samples > 275:\n",
    "        raise ValueError(\"Sample count cannot exceed 275 (testset size)\")\n",
    "    \n",
    "    print(f\"‚úì Using {n_samples} samples from depth2 testset\\n\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"‚úó Invalid sample input: {e}\")\n",
    "    raise\n",
    "\n",
    "# ========================================================\n",
    "# B. Data Preparation\n",
    "# ========================================================\n",
    "\n",
    "# Load depth2 test dataset\n",
    "X_test_depth2_full, y_test_depth2_full = load_depth2_data()\n",
    "\n",
    "# Select samples\n",
    "if n_samples < len(X_test_depth2_full):\n",
    "    # Random subset with fixed seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(X_test_depth2_full), size=n_samples, replace=False)\n",
    "    X_test_depth2_subset = X_test_depth2_full[indices]\n",
    "    y_test_depth2_subset = y_test_depth2_full[indices]\n",
    "    print(f\"‚úì Selected random subset of {n_samples} samples (seed=42)\")\n",
    "else:\n",
    "    X_test_depth2_subset = X_test_depth2_full\n",
    "    y_test_depth2_subset = y_test_depth2_full\n",
    "    print(f\"‚úì Using full testset ({n_samples} samples)\")\n",
    "\n",
    "# ========================================================\n",
    "# C. Baseline Evaluation (StatevectorEstimator)\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Evaluating StatevectorEstimator baseline...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Build depth2 model with StatevectorEstimator\n",
    "depth2_ansatz_sv = ansatz(5, 2)\n",
    "depth2_model_sv = HybridModel(depth2_ansatz_sv, 5)\n",
    "\n",
    "# Load depth2 weights\n",
    "load_depth2_weights(depth2_model_sv, strip_prefix=False)\n",
    "depth2_model_sv.eval()\n",
    "\n",
    "# Evaluate with timing\n",
    "X_test_tensor = torch.tensor(X_test_depth2_subset, dtype=torch.float32)\n",
    "\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    sv_predictions = depth2_model_sv(X_test_tensor).numpy().flatten()\n",
    "sv_time_total = time.time() - start_time\n",
    "sv_time = sv_time_total / n_samples  # Average per sample\n",
    "\n",
    "sv_predicted_labels = np.where(sv_predictions > 0, 1, -1)\n",
    "sv_accuracy = accuracy_score(y_test_depth2_subset, sv_predicted_labels)\n",
    "\n",
    "print(f\"‚úì Statevector Accuracy: {sv_accuracy:.4f} ({sv_accuracy*100:.2f}%)\")\n",
    "print(f\"‚úì Statevector Time (avg/sample): {sv_time:.6f}s\")\n",
    "print(f\"  Total time for {n_samples} samples: {sv_time_total:.4f}s\\n\")\n",
    "\n",
    "# ========================================================\n",
    "# D. Hardware Evaluation Loop\n",
    "# ========================================================\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"Evaluating IQM Hardware with varying shot counts...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Connect to IQM backend\n",
    "iqm_backend = connect_to_iqm_backend()\n",
    "print()  # Add spacing\n",
    "\n",
    "# Store results\n",
    "hw_results = []\n",
    "\n",
    "# Progress bar setup\n",
    "if has_tqdm:\n",
    "    pbar = tqdm(shot_counts, desc=\"Evaluating shot counts\", unit=\"config\")\n",
    "else:\n",
    "    pbar = shot_counts\n",
    "    print(f\"Progress: 0/{len(shot_counts)} shot configurations completed\")\n",
    "\n",
    "for idx, n_shots in enumerate(pbar):\n",
    "    try:\n",
    "        # Build hardware estimator\n",
    "        hw_estimator = IQMBackendEstimator(iqm_backend, options={\"shots\": n_shots})\n",
    "        \n",
    "        # Build depth2 quantum circuit for hardware\n",
    "        hw_ansatz = ansatz(5, 2)\n",
    "        hw_feature_map = HybridModel(hw_ansatz, 5).angle_encoding(5)\n",
    "        \n",
    "        hw_qc = QuantumCircuit(5)\n",
    "        hw_qc.compose(hw_feature_map, qubits=range(5), inplace=True)\n",
    "        hw_qc.compose(hw_ansatz, inplace=True)\n",
    "        \n",
    "        observable = SparsePauliOp.from_list([(\"I\" * 4 + \"Z\", 1)])\n",
    "        \n",
    "        hw_qnn = EstimatorQNN(\n",
    "            circuit=hw_qc,\n",
    "            observables=observable,\n",
    "            input_params=list(hw_feature_map.parameters),\n",
    "            weight_params=list(hw_ansatz.parameters),\n",
    "            estimator=hw_estimator\n",
    "        )\n",
    "        \n",
    "        hw_model = TorchConnector(hw_qnn)\n",
    "        \n",
    "        # Load weights with prefix stripping\n",
    "        load_depth2_weights(hw_model, strip_prefix=True)\n",
    "        \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            hw_predictions = hw_model(X_test_tensor).numpy().flatten()\n",
    "        \n",
    "        hw_predicted_labels = np.where(hw_predictions > 0, 1, -1)\n",
    "        hw_accuracy = accuracy_score(y_test_depth2_subset, hw_predicted_labels)\n",
    "        hw_qpu_time = hw_estimator.total_qpu_time / n_samples  # Average per sample\n",
    "        \n",
    "        # Store results (QPU time is average per sample)\n",
    "        hw_results.append({\n",
    "            'shots': n_shots,\n",
    "            'accuracy': hw_accuracy,\n",
    "            'qpu_time': hw_qpu_time  # Average time per sample\n",
    "        })\n",
    "        \n",
    "        # Update progress\n",
    "        if has_tqdm:\n",
    "            pbar.set_postfix({\n",
    "                'shots': n_shots,\n",
    "                'acc': f'{hw_accuracy:.4f}',\n",
    "                'QPU_time': f'{hw_qpu_time:.4f}s'  # Changed format for smaller numbers\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Progress: {idx+1}/{len(shot_counts)} | shots={n_shots} | acc={hw_accuracy:.4f} | QPU_time_per_sample={hw_qpu_time:.4f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó Error at {n_shots} shots: {e}\")\n",
    "        # Continue with other shot counts\n",
    "        hw_results.append({\n",
    "            'shots': n_shots,\n",
    "            'accuracy': None,\n",
    "            'qpu_time': None\n",
    "        })\n",
    "\n",
    "print(\"\\n‚úì Hardware evaluation complete!\\n\")\n",
    "\n",
    "# ========================================================\n",
    "# E. Visualization\n",
    "# ========================================================\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"Generating comparison graphs...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Extract data for plotting\n",
    "hw_shots = [r['shots'] for r in hw_results if r['accuracy'] is not None]\n",
    "hw_accuracies = [r['accuracy'] for r in hw_results if r['accuracy'] is not None]\n",
    "hw_times = [r['qpu_time'] for r in hw_results if r['qpu_time'] is not None]\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Figure 1: Shot Count vs Accuracy\n",
    "ax1.plot(hw_shots, hw_accuracies, 'o-', color='blue', linewidth=2, markersize=8, label='IQM Hardware')\n",
    "ax1.axhline(y=sv_accuracy, color='red', linestyle='--', linewidth=2, label='StatevectorEstimator (ideal)')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Shot Count (log scale)', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_title('Accuracy vs Shot Count\\n(depth2 testset)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "\n",
    "# Figure 2: Shot Count vs QPU Time (per sample)\n",
    "ax2.plot(hw_shots, hw_times, 'o-', color='green', linewidth=2, markersize=8, label='IQM Hardware')\n",
    "ax2.axhline(y=sv_time, color='orange', linestyle='--', linewidth=2, label='StatevectorEstimator')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Shot Count (log scale)', fontsize=12)\n",
    "ax2.set_ylabel('Time per Sample (seconds)', fontsize=12)\n",
    "ax2.set_title('Average Time per Sample vs Shot Count', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================================================\n",
    "# F. Summary Table\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Shot Count':<15} | {'Accuracy':<10} | {'Avg QPU Time/sample (s)':<25}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Statevector':<15} | {sv_accuracy:<10.4f} | {sv_time:<25.4f}\")\n",
    "for result in hw_results:\n",
    "    if result['accuracy'] is not None:\n",
    "        print(f\"{result['shots']:<15} | {result['accuracy']:<10.4f} | {result['qpu_time']:<25.4f}\")\n",
    "    else:\n",
    "        print(f\"{result['shots']:<15} | {'FAILED':<10} | {'N/A':<25}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQM Job Timing Distribution\n",
    "Visualize how time is distributed across different components of IQM job execution (QPU, compilation, queue, network, overhead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# IQM Job Timing Distribution Analysis\n",
    "# ========================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IQM JOB TIMING BREAKDOWN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select which shot count configuration to analyze\n",
    "print(\"\\nAvailable shot counts:\", [r['shots'] for r in hw_results if r['accuracy'] is not None])\n",
    "selected_shots = int(input(\"Enter shot count to analyze timing (or press Enter for last): \") or hw_results[-1]['shots'])\n",
    "\n",
    "# Find the corresponding estimator from the last evaluation loop\n",
    "# Note: We need to re-run evaluation or store estimators to access timing data\n",
    "# For now, we'll use the last hw_estimator from the loop\n",
    "\n",
    "if not hasattr(hw_estimator, 'timestamp_history') or not hw_estimator.timestamp_history:\n",
    "    print(\"‚ö†Ô∏è  No timing data available. Run the evaluation first.\")\n",
    "else:\n",
    "    # Extract timing data\n",
    "    qpu_times = []\n",
    "    compile_times = []\n",
    "    queue_times = []\n",
    "    network_times = []\n",
    "    \n",
    "    for t in hw_estimator.timestamp_history:\n",
    "        ts = t['raw_timestamps']\n",
    "        \n",
    "        # QPU execution time\n",
    "        if ts.get('execution_started') and ts.get('execution_ended'):\n",
    "            qpu_times.append((ts['execution_ended'] - ts['execution_started']).total_seconds())\n",
    "        \n",
    "        # Compilation time\n",
    "        if ts.get('compilation_started') and ts.get('compilation_ended'):\n",
    "            compile_times.append((ts['compilation_ended'] - ts['compilation_started']).total_seconds())\n",
    "        \n",
    "        # Queue time (waiting for QPU)\n",
    "        if ts.get('pending_execution') and ts.get('execution_started'):\n",
    "            queue_times.append((ts['execution_started'] - ts['pending_execution']).total_seconds())\n",
    "        \n",
    "        # Network time (upload + download)\n",
    "        net_time = 0\n",
    "        if ts.get('created') and ts.get('pending_compilation'):\n",
    "            net_time += (ts['pending_compilation'] - ts['created']).total_seconds()\n",
    "        if ts.get('ready') and ts.get('completed'):\n",
    "            net_time += (ts['completed'] - ts['ready']).total_seconds()\n",
    "        network_times.append(net_time)\n",
    "    \n",
    "    # Calculate totals\n",
    "    total_qpu = sum(qpu_times)\n",
    "    total_compile = sum(compile_times)\n",
    "    total_queue = sum(queue_times)\n",
    "    total_network = sum(network_times)\n",
    "    total_job = sum(t['job_time_total'] for t in hw_estimator.timestamp_history)\n",
    "    total_other = total_job - (total_qpu + total_compile + total_queue + total_network)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nNumber of jobs: {len(hw_estimator.timestamp_history)}\")\n",
    "    print(f\"Total job time: {total_job:.3f}s\")\n",
    "    print(\"\\nTime Breakdown:\")\n",
    "    print(f\"  QPU Execution:    {total_qpu*1000:8.2f} ms  ({100*total_qpu/total_job:5.1f}%)\")\n",
    "    print(f\"  Compilation:      {total_compile*1000:8.2f} ms  ({100*total_compile/total_job:5.1f}%)\")\n",
    "    print(f\"  Queue (waiting):  {total_queue*1000:8.2f} ms  ({100*total_queue/total_job:5.1f}%)\")\n",
    "    print(f\"  Network (I/O):    {total_network*1000:8.2f} ms  ({100*total_network/total_job:5.1f}%)\")\n",
    "    print(f\"  Other (overhead): {total_other*1000:8.2f} ms  ({100*total_other/total_job:5.1f}%)\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    labels = ['QPU Execution', 'Compilation', 'Queue', 'Network', 'Other']\n",
    "    sizes = [total_qpu, total_compile, total_queue, total_network, total_other]\n",
    "    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#dfe6e9']\n",
    "    explode = (0.1, 0, 0, 0, 0)  # Emphasize QPU\n",
    "    \n",
    "    ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "            shadow=True, startangle=90)\n",
    "    ax1.set_title(f'IQM Job Time Distribution\\n({selected_shots} shots, {len(hw_estimator.timestamp_history)} jobs)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Bar chart\n",
    "    ax2.bar(labels, [s*1000 for s in sizes], color=colors)\n",
    "    ax2.set_ylabel('Time (ms)', fontsize=12)\n",
    "    ax2.set_title('Time Breakdown by Component', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (PLEASE GAWD)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
