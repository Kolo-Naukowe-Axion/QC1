{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLzI6vhj-pd"
      },
      "source": [
        "# Quantum Classfier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-UIxi_YPLhZ_",
        "outputId": "ab9b1f08-0b07-4100-8b4b-301cbd78d2f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.2.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.3)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.6.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-1.4.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting scipy>=1.5 (from qiskit)\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.12/dist-packages (from qiskit_machine_learning) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.8.4-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-1.4.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.6.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, stevedore, scipy, rustworkx, qiskit, qiskit_machine_learning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "Successfully installed qiskit-1.4.5 qiskit_machine_learning-0.8.4 rustworkx-0.17.1 scipy-1.15.3 stevedore-5.6.0 symengine-0.13.0\n",
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.11.12)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install qiskit qiskit_machine_learning\n",
        "%pip install ucimlrepo\n",
        "%pip install torch\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKSJGRyG0ouM"
      },
      "outputs": [],
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.circuit.library import ZZFeatureMap\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "import numpy as np\n",
        "# from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit.primitives import Estimator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient\n",
        "import sys          # Standard library module for system-specific parameters and functions\n",
        "import subprocess   # Standard library module for spawning new processes\n",
        "from sklearn.preprocessing import MinMaxScaler # Importuje MinMaxScaler do skalowania danych\n",
        "from sklearn.model_selection import train_test_split # Importuje train_test_split do podziału danych\n",
        "from ucimlrepo import fetch_ucirepo     # Importuje fetch_ucirepo do pobierania zestawów danych z UCI ML Repository\n",
        "from sklearn.utils import shuffle\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enUz4SJl6Fnh",
        "outputId": "a939e096-a4b1-40b3-dff6-31060ed82136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def ensure_package(pkg_name, import_name=None):\n",
        "    import_name = import_name or pkg_name\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "    except ImportError:\n",
        "        print(f'Instalowanie {pkg_name}...')\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
        "        print(f'Zakończono instalację {pkg_name}')\n",
        "    except Exception as e:\n",
        "        print(f\"Wystąpił nieoczekiwany błąd podczas sprawdzania pakietu {pkg_name}: {e}\")\n",
        "\n",
        "\n",
        "ensure_package('numpy')\n",
        "ensure_package('scikit-learn', 'sklearn')\n",
        "ensure_package('ucimlrepo')\n",
        "\n",
        "\n",
        "\n",
        "# Funkcja przygotowująca dane\n",
        "def prepare_data():\n",
        "\n",
        "    # Pobiera zestaw danych 'banknote authentication' z UCI ML Repository\n",
        "    banknote_authentication = fetch_ucirepo(id=267)\n",
        "    # Wyodrębnia cechy (zmienne niezależne) z zestawu danych\n",
        "    X = banknote_authentication.data.features\n",
        "    # Wyodrębnia zmienną docelową (zmienna zależna) z zestawu danych\n",
        "    y = banknote_authentication.data.targets\n",
        "\n",
        "    X = X.to_numpy() # Konwertuje cechy na tablicę NumPy\n",
        "    y = y.to_numpy().ravel() # Konwertuje zmienną docelową na spłaszczoną tablicę NumPy\n",
        "\n",
        "    # Dzieli dane na zestawy treningowe i testowe\n",
        "    # test_size=0.2 oznacza 20% danych dla testowania, random_state zapewnia powtarzalność podziału\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Skalowanie danych\n",
        "    # Inicjalizuje MinMaxScaler, który skaluje cechy do zakresu od 0 do pi\n",
        "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "    # Dopasowuje skaler do danych treningowych i jednocześnie je skaluje\n",
        "    # 'fit_transform' jest używane na danych treningowych, aby skaler nauczył się min/max wartości\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    # Skaluje dane testowe przy użyciu parametrów nauczonych z danych treningowych\n",
        "    # 'transform' jest używane na danych testowych, aby uniknąć wycieku danych\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Zwraca przygotowane i przeskalowane dane\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# Uruchamia funkcję prepare_data() tylko wtedy, gdy skrypt jest wykonywany bezpośrednio\n",
        "if __name__ == \"__main__\":\n",
        "    # Wywołuje funkcję przygotowującą dane i przypisuje zwrócone wartości do zmiennych\n",
        "    X_tr, X_te, y_tr, y_te = prepare_data()\n",
        "    print(\"test\") # Wypisuje \"test\" do konsoli, sygnalizując zakończenie operacji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVvwAGxS8oGq"
      },
      "source": [
        "Poniższy kod odpowiada za anstaz. Powstał on w oparciu o bibliteke Qiskit i korzysta z wbudowanych w nią funkcji, takich jak ParameterVektor służący do łatwego iterowania po parametrach bramek rotacyjnych. Sieć zakładay wykożystanie 4 qbitów oraz parzystej ilości warst. Każda warstwa składa się za podwarstwy niezależnych bramek oraz podwarstwy splątania.\n",
        "\n",
        "\n",
        "Indeksy tych parametrów są numerowane od zera, a konstrukcja \" j*n_qubits * 4 \" upewnia się, że każda warstwa kożysta jedynie ze swoich parametrów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nLVltQH8rKQ",
        "outputId": "5d490f93-8005-4cd3-f503-edd491866ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-1032776977.py, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1032776977.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    theta = ParameterVector('θ', 8*depth)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "def ansatz(n_qubits, depth):\n",
        "    \"\"\"\n",
        "    The code below constructs the ansatz. It is built using the Qiskit library\n",
        "    and utilizes its built-in tools, such as ParameterVector, to easily iterate\n",
        "    over rotation gate parameters.\n",
        "\n",
        "    The implementation assumes the use of 4 qubits and an even number of layers\n",
        "    (depth). Each layer consists of a sub-layer of independent gates and a\n",
        "    sub-layer of entanglement.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    Hypothesis:\n",
        "    Implementing a new entanglement layer arrangement with two unique ring\n",
        "    topologies will ensure that the final gate operation directly influences\n",
        "    the measured qubit (qubit 0).\n",
        "\n",
        "    Explanation:\n",
        "    Due to the measurement being performed specifically on the zeroth qubit,\n",
        "    the entanglement strategy is critical. We introduce two distinct ring\n",
        "    layouts (one for CRX, one for CRY). This specific arrangement is designed\n",
        "    to guarantee that the last applied gate has a direct impact on the measured\n",
        "    qubit, preventing the issue where final operations might be lost or\n",
        "    ineffective relative to the readout.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a vector of learnable parameters.\n",
        "    # Total parameters = 8 * depth (16 per full loop iteration).\n",
        "    theta = ParameterVector('θ', 8 * depth)\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    # The loop iterates (depth // 2) times.\n",
        "    # This structure requires 'depth' to be even to execute full blocks.\n",
        "    for j in range(depth // 2):\n",
        "\n",
        "        # --- Layer 1: Independent RY rotations ---\n",
        "        # Apply RY rotation to every qubit using the first set of parameters for this block.\n",
        "        for i in range(n_qubits):\n",
        "            qc.ry(theta[j * n_qubits * 4 + i], i)\n",
        "\n",
        "        qc.barrier()\n",
        "\n",
        "        # --- Layer 2: Entanglement (CRX) ---\n",
        "        # Controlled-RX gates creating a modified ring topology.\n",
        "        qc.crx(theta[j*n_qubits*4+7], 3, 2) #\n",
        "        qc.crx(theta[j*n_qubits*4+4], 0, 3) # Modified code fragment\n",
        "        qc.crx(theta[j*n_qubits*4+5], 1, 0) #\n",
        "        qc.crx(theta[j*n_qubits*4+6], 2, 1) #\n",
        "        qc.barrier()\n",
        "\n",
        "        # --- Layer 3: Independent RX rotations ---\n",
        "        # Apply RX rotation to every qubit using the second set of parameters (offset by 8).\n",
        "        for i in range(n_qubits):\n",
        "            qc.rx(theta[j * n_qubits * 4 + 8 + i], i)\n",
        "        qc.barrier()\n",
        "\n",
        "        # --- Layer 4: Entanglement (CRY) ---\n",
        "        # Controlled-RX gates creating a modified ring topology.\n",
        "        qc.crx(theta[j*n_qubits*4+7], 0, 1) #\n",
        "        qc.crx(theta[j*n_qubits*4+4], 1, 2) # Modified code fragment\n",
        "        qc.crx(theta[j*n_qubits*4+5], 2, 3) #\n",
        "        qc.crx(theta[j*n_qubits*4+6], 3, 0) #\n",
        "        qc.barrier()\n",
        "\n",
        "    return qc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dbdb644"
      },
      "outputs": [],
      "source": [
        "\n",
        "class HybridModel:\n",
        "    def __init__(self, ansatz_circuit, num_qubits):\n",
        "\n",
        "        # we inicialize the variables\n",
        "        self.num_qubits = num_qubits\n",
        "\n",
        "        '''now we perform data encoding using ZZFetureMap, briefly it consist of three layers\n",
        "        1. hadamard - puts all the qubits in superposition state |+>\n",
        "        2. Z-Rotations - rotates each qubit individually based on input features Rz(x)\n",
        "        3. ZZ-Rotations - it entangles qubits by rotating them based on the relationship between two features\n",
        "\n",
        "        reps=1, we do the circuit of encoding only once. We can try and change that to 2 but it gets deeper\n",
        "        '''\n",
        "        self.feature_map = ZZFeatureMap(feature_dimension=num_qubits, reps=1)\n",
        "\n",
        "        # Initalizing quantum circuit. Here we are connecting our feature map (data) and ansatz\n",
        "        self.qc = QuantumCircuit(num_qubits)\n",
        "        self.qc.compose(self.feature_map,qubits=range(num_qubits), inplace=True)\n",
        "        self.qc.compose(ansatz_circuit, inplace=True)\n",
        "\n",
        "\n",
        "        '''\n",
        "        So that is a crucial step. Firstly, we inicialize parameters. Our quantum model cannot tell whether the number came from ansatz or feature.\n",
        "        That is why here we sort them into two lists. If the number came from feature_map, then it will be a feature and the other way around.\n",
        "\n",
        "        '''\n",
        "        final_circuit_params = self.qc.parameters\n",
        "\n",
        "        # creating dicts with names of the variables to then check them in our loop\n",
        "        feature_map_names = {p.name for p in self.feature_map.parameters}\n",
        "        ansatz_names = {p.name for p in ansatz_circuit.parameters}\n",
        "\n",
        "        self.final_input_params = []\n",
        "        self.final_weight_params = []\n",
        "\n",
        "        for p in final_circuit_params:\n",
        "            if p.name in feature_map_names:\n",
        "                self.final_input_params.append(p)\n",
        "            elif p.name in ansatz_names:\n",
        "                self.final_weight_params.append(p)\n",
        "\n",
        "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
        "\n",
        "        '''Estimator takes ansatz, observables and parameters (data and weights), returns the Expectation value.'''\n",
        "\n",
        "\n",
        "        # estimator = StatevectorEstimator()\n",
        "        estimator = Estimator()\n",
        "        # creating a gradient for backward\n",
        "        gradient = ParamShiftEstimatorGradient(estimator)\n",
        "        self.qnn = EstimatorQNN(\n",
        "            circuit=self.qc,\n",
        "            observables=observable,\n",
        "            input_params=self.final_input_params,\n",
        "            weight_params=self.final_weight_params,\n",
        "            estimator=estimator,\n",
        "            gradient = gradient\n",
        "        )\n",
        "\n",
        "\n",
        "    # forward: gives the Estimator data and weights, sets the qubit angles, runs gates and measures the result\n",
        "    def forward(self, x, weights):\n",
        "        return self.qnn.forward(x, weights)\n",
        "\n",
        "    # backward In Quantum ML it actually runs forward once again but with a little change\n",
        "    # Firstly it shifts the angles by pi/2 and runs the circuit, then -pi/2 and runs the circuit\n",
        "    # It calculates the difference and it's the gradient, we only return weight_grads because we dont need input_grads\n",
        "    def backward(self, x, weights):\n",
        "        _, weight_grads = self.qnn.backward(x, weights)\n",
        "        if weight_grads is None:\n",
        "            # If it fails, return zeros to prevent the loop from crashing\n",
        "            print(\"Warning: Gradients were None. Returning Zeros.\")\n",
        "            return np.zeros((x.shape[0], len(weights)))\n",
        "        return weight_grads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdIU8v5o1rxb",
        "outputId": "6555b9ec-4474-41f3-f0a9-157d4ca20a64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights initialized. Shape: (32,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1327229255.py:48: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
            "  estimator = Estimator()\n",
            "/tmp/ipython-input-1327229255.py:50: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  gradient = ParamShiftEstimatorGradient(estimator)\n",
            "/tmp/ipython-input-1327229255.py:51: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  self.qnn = EstimatorQNN(\n"
          ]
        }
      ],
      "source": [
        "my_ansatz = ansatz(4, 4)\n",
        "qnn = HybridModel(\n",
        "    ansatz_circuit=my_ansatz,\n",
        "    num_qubits=4,\n",
        ")\n",
        "\n",
        "\n",
        "# Inicializing the weights\n",
        "num_weights = qnn.qnn.num_weights\n",
        "rng = np.random.default_rng(seed=42)\n",
        "weights = 2 * np.pi * rng.random(num_weights)\n",
        "weights = weights.flatten()\n",
        "\n",
        "print(f\"Weights initialized. Shape: {weights.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVX_eldyLhaB",
        "outputId": "03f1f8a5-15f8-4693-dd58-62b986adccbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pobieranie danych z funkcji prepare_data()...\n",
            "Dane gotowe. Liczba próbek treningowych: 1097\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.02\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "acc_history = []\n",
        "\n",
        "print(\"Pobieranie danych z funkcji prepare_data()...\")\n",
        "\n",
        "# Zwraca ona już przeskalowane cechy \"X\" w zakresie [0, pi], więc z X nie musimy juz nic robic.\n",
        "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
        "\n",
        "# Funkcja prepare_data zwraca etykiety {0, 1}.\n",
        "# Nasz model HybridModel używa pomiaru Z (wartości od -1 do 1).\n",
        "# Konwertujemy: 0 -> -1 oraz 1 -> 1\n",
        "y_train = 2 * y_train_raw - 1\n",
        "y_test = 2 * y_test_raw - 1\n",
        "\n",
        "# Upewniamy się, że typy danych to float32 (najlepsze dla PyTorch/NumPy)\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "print(f\"Dane gotowe. Liczba próbek treningowych: {len(X_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H9hpIPaLhaB",
        "outputId": "fab84600-a9b7-440d-a8ad-59a05fa8c270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start treningu... Model: HybridModel, Epoki: 20, LR: 0.02\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1759057221.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Obliczenie gradientów wag (zwraca numpy array)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mgrads_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_weights_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# MSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1327229255.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, weights)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# It calculates the difference and it's the gradient, we only return weight_grads because we dont need input_grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_grads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# If it fails, return zeros to prevent the loop from crashing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0minput_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         input_grad_reshaped, weight_grad_reshaped = self._validate_backward_output(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py\u001b[0m in \u001b[0;36m_backward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mQiskitMachineLearningError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Estimator job failed. {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/qiskit/primitives/primitive_job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResultT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_submitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJobStatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# PRZYGOTOWANIE OPTYMALIZATORA ADAM\n",
        "# Tworzymy Tensor PyTorcha, który będzie przechowywał wagi i historię gradientów\n",
        "weights_tensor = torch.tensor(weights, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "# Używamy adam optimizer\n",
        "optimizer = torch.optim.Adam([weights_tensor], lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Start treningu... Model: HybridModel, Epoki: {EPOCHS}, LR: {LEARNING_RATE}\")# GŁÓWNA PĘTLA TRENINGOWA\n",
        "for epoch in range(EPOCHS):\n",
        "    # Tasowanie danych w każdej epoce\n",
        "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=epoch)\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    batches_count = 0\n",
        "\n",
        "    # Iteracja po batchach\n",
        "    for i in range(0, len(X_train), BATCH_SIZE):\n",
        "        X_batch = X_train_shuffled[i:i + BATCH_SIZE]\n",
        "        y_batch = y_train_shuffled[i:i + BATCH_SIZE]\n",
        "\n",
        "        # Konwersja wag na NumPy dla Qiskita (bo Qiskit nie przyjmuje tensorów PyTorcha)\n",
        "        current_weights_numpy = weights_tensor.detach().numpy()\n",
        "\n",
        "        # forward\n",
        "        # Predykcja modelu (zwraca wartości od -1 do 1)\n",
        "        pred = qnn.forward(X_batch, current_weights_numpy)\n",
        "\n",
        "        # backward\n",
        "        # Obliczenie gradientów wag (zwraca numpy array)\n",
        "        grads_numpy = qnn.backward(X_batch, current_weights_numpy)\n",
        "\n",
        "        # MSE\n",
        "        # Różnica: predykcja - prawda\n",
        "        # Reshape tylko dla y_batch, bo pred wychodząc z QNN jest juz w kształcie (32,1)\n",
        "        # Reshape od flatten rozni się tym ze flatten spłaszcza wszystko do jednego wymiaru i towrzy prostą listę liczb np. [1,2,3]\n",
        "        # reshape(-1,1) natomiast układa te same liczby w pionową kolumnę np. [[1], [2], [3]], reshape(3,1)- 3 wiersze i 1 kolumna\n",
        "        # reshape(-1,1) -1 oznacza ze bedzie 1 kolumna i parametr -1 zamienia sie automatycznie w BATCH_SIZE czyli 32\n",
        "        diff = pred - y_batch.reshape(-1, 1)\n",
        "        loss = np.mean(diff ** 2)\n",
        "\n",
        "        # Chain Rule: pochodna MSE = 2 * (pred - y)\n",
        "        # 2 * diff bo to pochodna z (pred - y)^2\n",
        "        grad_modifier = 2 * diff\n",
        "\n",
        "        # OBLICZANIE GRADIENTU\n",
        "        # Usuwamy zbędny środkowy wymiar (z (32, 1, wagi) na (32, wagi))\n",
        "        # Dzięki temu mamy prostą macierz: wiersz = próbka, kolumna = gradient wagi\n",
        "        grads_2d = grads_numpy.reshape(grads_numpy.shape[0], -1)\n",
        "\n",
        "        # Ważymy gradienty (Chain Rule)\n",
        "        # Każdy wiersz gradientów mnożymy przez błąd danej próbki (grad_modifier)\n",
        "        weighted_grads = grad_modifier * grads_2d\n",
        "\n",
        "        # Obliczamy średnią po całym batchu (axis=0 to wiersze)\n",
        "        # To daje nam jeden wektor gradientów do aktualizacji wag\n",
        "        batch_grads_numpy = np.mean(weighted_grads, axis=0)\n",
        "\n",
        "        # AKTUALIZACJA WAG\n",
        "        # Czyścimy stare gradienty\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Dajemy nasz ręcznie policzony gradient do tensora PyTorcha\n",
        "        weights_tensor.grad = torch.from_numpy(batch_grads_numpy).float()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss\n",
        "        batches_count += 1\n",
        "\n",
        "    # Zapisanie wytrenowanych wag z powrotem do zmiennej numpy\n",
        "    weights = weights_tensor.detach().numpy()\n",
        "\n",
        "    test_outputs = qnn.forward(X_test, weights)\n",
        "    test_diff = test_outputs - y_test.reshape(-1, 1)\n",
        "    test_loss = np.mean(test_diff ** 2)\n",
        "\n",
        "    # zamiast predicted = (test_outputs > 0.5).astype(int).flatten()\n",
        "    # bo nasze etykiety y_test to [-1, 1] a nie [0, 1]\n",
        "    # Używamy np.where: jeśli wynik > 0 to klasa 1, w przeciwnym razie klasa -1.\n",
        "    predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
        "\n",
        "    test_accuracy = np.mean(predicted == y_test.flatten())\n",
        "\n",
        "    avg_loss = epoch_loss / batches_count\n",
        "    train_loss_history.append(avg_loss)\n",
        "    test_loss_history.append(test_loss)\n",
        "    acc_history.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wCWSEFnLhaB"
      },
      "outputs": [],
      "source": [
        "test_outputs = qnn.forward(X_test, weights)\n",
        "predicted = np.where(test_outputs > 0, 1, -1).flatten() # Tutaj tez uzywamy np.where\n",
        "\n",
        "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
        "c_matrix_display.plot()\n",
        "\n",
        "epochs = range(1, EPOCHS + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
        "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12 (Qiskit)",
      "language": "python",
      "name": "qiskit_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}