{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Kolo-Naukowe-Axion/QC1/blob/main/quantum_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jLzI6vhj-pd"
   },
   "source": [
    "##Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReVDTmxqlXfC",
    "outputId": "9dd5aaa7-a35b-4f56-a8d5-74b75c686dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in /Users/jkw/qiskit_env/lib/python3.12/site-packages (1.4.5)\n",
      "Requirement already satisfied: qiskit_machine_learning in /Users/jkw/qiskit_env/lib/python3.12/site-packages (0.8.4)\n",
      "Requirement already satisfied: rustworkx>=0.15.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (0.17.1)\n",
      "Requirement already satisfied: numpy<3,>=1.17 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.5 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (1.15.3)\n",
      "Requirement already satisfied: sympy>=1.3 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (1.14.0)\n",
      "Requirement already satisfied: dill>=0.3 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (2.9.0.post0)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (5.6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (4.15.0)\n",
      "Requirement already satisfied: symengine<0.14,>=0.11 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit) (0.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit_machine_learning) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=40.1 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from qiskit_machine_learning) (80.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ucimlrepo in /Users/jkw/qiskit_env/lib/python3.12/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from ucimlrepo) (2.3.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from ucimlrepo) (2025.11.12)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/jkw/qiskit_env/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/jkw/qiskit_env/lib/python3.12/site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jkw/qiskit_env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qiskit qiskit_machine_learning\n",
    "%pip install ucimlrepo\n",
    "%pip install torch\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LKSJGRyG0ouM"
   },
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.primitives import StatevectorEstimator\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.gradients import ParamShiftEstimatorGradient\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "import sys          # Standard library module for system-specific parameters and functions\n",
    "import subprocess   # Standard library module for spawning new processes\n",
    "from sklearn.preprocessing import MinMaxScaler # Importuje MinMaxScaler do skalowania danych\n",
    "from sklearn.model_selection import train_test_split # Importuje train_test_split do podziału danych\n",
    "from ucimlrepo import fetch_ucirepo     # Importuje fetch_ucirepo do pobierania zestawów danych z UCI ML Repository\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "enUz4SJl6Fnh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "\n",
    "def ensure_package(pkg_name, import_name=None):\n",
    "    import_name = import_name or pkg_name\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
    "\n",
    "# Ensure all requirements are met\n",
    "ensure_package('numpy')\n",
    "ensure_package('scikit-learn', 'sklearn')\n",
    "ensure_package('ucimlrepo')\n",
    "ensure_package('qiskit')\n",
    "\n",
    "def prepare_data():\n",
    "    \"\"\"\n",
    "    Fetches the banknote authentication dataset and returns scaled train/test splits.\n",
    "    Features are scaled to [0, pi] specifically for Angle Encoding.\n",
    "    \"\"\"\n",
    "    banknote_authentication = fetch_ucirepo(id=267)\n",
    "    X = banknote_authentication.data.features.to_numpy()\n",
    "    y = banknote_authentication.data.targets.to_numpy().ravel()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scaling to [0, pi] ensures data maps perfectly to Ry rotation angles\n",
    "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "\n",
    "# Global availability of data\n",
    "X_tr, X_te, y_tr, y_te = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pz4kqrFfANdX"
   },
   "outputs": [],
   "source": [
    "def ansatz(n_qubits, depth):\n",
    "    \"\"\"\n",
    "    The code below constructs the ansatz. It is built using the Qiskit library\n",
    "    and utilizes its built-in tools, such as ParameterVector, to easily iterate\n",
    "    over rotation gate parameters.\n",
    "\n",
    "    The implementation assumes the use of 4 qubits and an even number of layers\n",
    "    (depth). Each layer consists of a sub-layer of independent gates and a\n",
    "    sub-layer of entanglement.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a vector of learnable parameters.\n",
    "    # Total parameters = 8 * depth (16 per full loop iteration).\n",
    "    theta = ParameterVector('θ', 8 * depth)\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    # The loop iterates (depth // 2) times.\n",
    "    # This structure requires 'depth' to be even to execute full blocks.\n",
    "    for j in range(depth // 2):\n",
    "\n",
    "\n",
    "        # -------- Layer 1 --------\n",
    "\n",
    "        # --- Sub-layer: Independent RY rotations --\n",
    "        # Apply RY rotation to every qubit using the first set of parameters for this block.\n",
    "        for i in range(n_qubits):\n",
    "            qc.ry(theta[j * n_qubits * 4 + i], i)\n",
    "\n",
    "        # --- Sub-layer: Entanglement (CRX) ---\n",
    "        # Controlled-RX gates creating a specific ring topology.\n",
    "        qc.crx(theta[j * n_qubits * 4 + 4], 3, 0)\n",
    "        qc.crx(theta[j * n_qubits * 4 + 5], 2, 3)\n",
    "        qc.crx(theta[j * n_qubits * 4 + 6], 1, 2)\n",
    "        qc.crx(theta[j * n_qubits * 4 + 7], 0, 1)\n",
    "\n",
    "\n",
    "        # -------- Layer 2 --------\n",
    "\n",
    "        # --- Sub-layer: Independent RX rotations ---\n",
    "        # Apply RX rotation to every qubit using the second set of parameters (offset by 8).\n",
    "        for i in range(n_qubits):\n",
    "            qc.rx(theta[j * n_qubits * 4 + 8 + i], i)\n",
    "\n",
    "        # --- Sub-layer: Entanglement (CRY) ---\n",
    "        # Controlled-RY gates creating a different ring topology.\n",
    "        qc.cry(theta[j * n_qubits * 4 + 12], 3, 2)\n",
    "        qc.cry(theta[j * n_qubits * 4 + 13], 0, 3)\n",
    "        qc.cry(theta[j * n_qubits * 4 + 14], 1, 0)\n",
    "        qc.cry(theta[j * n_qubits * 4 + 15], 2, 1)\n",
    "\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z_JEkN9KJ-Fh"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The code below constructs the class HybridModel. It is built using the Qiskit and Pytorch library and\n",
    "    and utilizes its built-in tools, to create a model connecting classical and quantum computing.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, ansatz_circuit, num_qubits):\n",
    "        super().__init__()\n",
    "        self.feature_map = self.angle_encoding(num_qubits)\n",
    "\n",
    "        # Connecting the quantum circuit. Connecting our feature map (data) and ansatz\n",
    "        self.qc = QuantumCircuit(num_qubits)\n",
    "        self.qc.compose(self.feature_map, qubits=range(num_qubits), inplace=True)\n",
    "        self.qc.compose(ansatz_circuit, inplace=True)\n",
    "\n",
    "        # Firstly, we inicialize parameters. Our quantum model cannot tell whether the number came from ansatz or feature.\n",
    "        # That is why here we sort them into two lists. If the number came from feature_map, then it will be a feature and the other way around.\n",
    "        input_params = list(self.feature_map.parameters)\n",
    "        weight_params = list(ansatz_circuit.parameters)\n",
    "\n",
    "        '''\n",
    "        Measure the Z-operator (spin) on the very first qubit (q_0) and ignore all the other qubits.\n",
    "        Qiskit reads the string in a reversed order, that is why the Z gate is on the end.\n",
    "        SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)]) converts string into a mathematical matrix that Qiskit can use for calculations\n",
    "        Coefficient = 1 is a weight we multiply our result by. In QML it is mostly set to 1\n",
    "        '''\n",
    "\n",
    "        observable = SparsePauliOp.from_list([(\"I\" * (num_qubits - 1) + \"Z\", 1)])\n",
    "\n",
    "        # Estimator takes ansatz, observables and parameters (data and weights), returns the Expectation value.\n",
    "        # !!!! CHANGE WHEN USING ON QUANTUM COMPUTER\n",
    "        # Needed when running quantum simulations, it should be changed when implementing on real quantum computer\n",
    "        estimator = StatevectorEstimator()\n",
    "\n",
    "        # Compute the gradients of the sampling probability by the Parameter Shift Rule.\n",
    "        gradient = ParamShiftEstimatorGradient(estimator)\n",
    "\n",
    "\n",
    "        '''\n",
    "        The EstimatorQNN\n",
    "        This class from Qiskit Machine Learning is used to instantiate the quantum neural network.\n",
    "        It leverages the Qiskit Primitives (Estimator) to efficiently calculate expectation values\n",
    "        of the quantum circuit. This allows the model to output continuous, differentiable values (gradients)\n",
    "        required for backpropagation in hybrid quantum-classical training.\n",
    "        '''\n",
    "\n",
    "        self.qnn = EstimatorQNN(\n",
    "            circuit=self.qc,\n",
    "            observables=observable,\n",
    "            input_params=input_params,\n",
    "            weight_params=weight_params,\n",
    "            estimator=estimator,\n",
    "            gradient=gradient\n",
    "        )\n",
    "\n",
    "        '''\n",
    "        TORCH CONNECTOR\n",
    "        This line initializes the TorchConnector, which serves as a bridge between Qiskit and PyTorch. It wraps the Quantum Neural Network (QNN)\n",
    "        to make it function as a standard, differentiable PyTorch module (nn.Module).\n",
    "        This integration allows the quantum parameters to be optimized using standard PyTorch tools like\n",
    "        the Adam optimizer and automatic differentiation.\n",
    "        '''\n",
    "        self.quantum_layer = TorchConnector(self.qnn)\n",
    "\n",
    "        \"\"\"\n",
    "        Creates a Feature Map circuit using Angle Encoding. It maps classical input vectors\n",
    "        to the quantum space by applying Ry(theta) rotations on each qubit,\n",
    "        where the rotation angle theta corresponds to the input feature value.\n",
    "        This effectively encodes the data into the amplitudes of the quantum state\n",
    "        \"\"\"\n",
    "\n",
    "    def angle_encoding(self, num_qubits):\n",
    "        qc_data = QuantumCircuit(num_qubits)\n",
    "        input_params = ParameterVector('x', num_qubits)\n",
    "        for i in range(num_qubits):\n",
    "            qc_data.ry(input_params[i], i)\n",
    "        return qc_data\n",
    "\n",
    "    '''\n",
    "    This function acts as the main execution path. When the model receives data,\n",
    "    the forward function passes it into the quantum layer to be processed.\n",
    "    The quantum layer calculates the result based on the current circuit parameters and returns the prediction.\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return self.quantum_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dv_mmuC3lXfL",
    "outputId": "5db1ddd1-0af8-4896-e5e5-72b5d5e0e0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data ready. Number of training samples: 1097\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "X_train, X_test, y_train_raw, y_test_raw = prepare_data()\n",
    "\n",
    "y_train = 2 * y_train_raw - 1\n",
    "y_test = 2 * y_test_raw - 1\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "print(f\"Data ready. Number of training samples: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vbZY4sy_Dzuh"
   },
   "outputs": [],
   "source": [
    "# --- Preparing the DataLoader ---\n",
    "\n",
    "# Data conversion to tensors for PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Creating a dataset with X_train_tensor and Y_train_tensor\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Creating a DataLoader, which now automatically handles shuffle in the training loop\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQpegINFKm1M",
    "outputId": "517e968a-f613-42a8-c11f-f359076be285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training... Epochs: 20\n",
      "Epoch 1/20 | Avg loss: 0.8056 | Test Acc: 0.7164\n",
      "Epoch 2/20 | Avg loss: 0.5673 | Test Acc: 0.7600\n",
      "Epoch 3/20 | Avg loss: 0.4716 | Test Acc: 0.8218\n",
      "Epoch 4/20 | Avg loss: 0.4201 | Test Acc: 0.8473\n",
      "Epoch 5/20 | Avg loss: 0.4039 | Test Acc: 0.8509\n",
      "Epoch 6/20 | Avg loss: 0.3959 | Test Acc: 0.8691\n",
      "Epoch 7/20 | Avg loss: 0.3921 | Test Acc: 0.8655\n",
      "Epoch 8/20 | Avg loss: 0.3888 | Test Acc: 0.8655\n",
      "Epoch 9/20 | Avg loss: 0.3954 | Test Acc: 0.8655\n",
      "Epoch 10/20 | Avg loss: 0.3910 | Test Acc: 0.8727\n",
      "Epoch 11/20 | Avg loss: 0.3914 | Test Acc: 0.8655\n",
      "Epoch 12/20 | Avg loss: 0.3940 | Test Acc: 0.8655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m output = model(X_batch)         \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m     23\u001b[39m loss = loss_function(output, y_batch) \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                 \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[32m     25\u001b[39m optimizer.step()                \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[32m     27\u001b[39m epoch_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/torch/autograd/function.py:315\u001b[39m, in \u001b[36mBackwardCFunction.apply\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mImplementing both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbackward\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvjp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for a custom \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFunction is not allowed. You should only implement one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    312\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mof them.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m     )\n\u001b[32m    314\u001b[39m user_fn = vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function.vjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/qiskit_machine_learning/connectors/torch_connector.py:229\u001b[39m, in \u001b[36m_TorchNNFunction.backward\u001b[39m\u001b[34m(ctx, grad_output)\u001b[39m\n\u001b[32m    226\u001b[39m     grad_output = grad_output.view(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# evaluate QNN gradient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m input_grad, weights_grad = \u001b[43mneural_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ctx.sparse:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:257\u001b[39m, in \u001b[36mNeuralNetwork.backward\u001b[39m\u001b[34m(self, input_data, weights)\u001b[39m\n\u001b[32m    255\u001b[39m input_, shape = \u001b[38;5;28mself\u001b[39m._validate_input(input_data)\n\u001b[32m    256\u001b[39m weights_ = \u001b[38;5;28mself\u001b[39m._validate_weights(weights)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m input_grad, weight_grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m input_grad_reshaped, weight_grad_reshaped = \u001b[38;5;28mself\u001b[39m._validate_backward_output(\n\u001b[32m    260\u001b[39m     input_grad, weight_grad, shape\n\u001b[32m    261\u001b[39m )\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m input_grad_reshaped, weight_grad_reshaped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/qiskit_machine_learning/neural_networks/estimator_qnn.py:364\u001b[39m, in \u001b[36mEstimatorQNN._backward\u001b[39m\u001b[34m(self, input_data, weights)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         results = \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m QiskitMachineLearningError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEstimator job failed. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/qiskit_env/lib/python3.12/site-packages/qiskit/primitives/primitive_job.py:51\u001b[39m, in \u001b[36mPrimitiveJob.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ResultT:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_submitted()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Defining a loss function (note for Axion, it it the same as Michał calculated manually with diff**2)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Inicializing the model\n",
    "final_ansatz = ansatz(4, 2)\n",
    "model = HybridModel(final_ansatz, 4)\n",
    "\n",
    "# Initializing the ADAM optimizer\n",
    "# Now that Our HybridModel is written in Pytorch, optimizer can access the paramiters directly\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Starting training... Epochs: {EPOCHS}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    batches_count = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()           # Reset gradients\n",
    "        output = model(X_batch)         # Forward\n",
    "        loss = loss_function(output, y_batch) # Loss\n",
    "        loss.backward()                 # Backward\n",
    "        optimizer.step()                # Update weights\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        batches_count += 1\n",
    "\n",
    "    # Evaluation on tensors\n",
    "    with torch.no_grad(): # To test our model we turn off the gradients\n",
    "\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = loss_function(test_outputs, y_test_tensor).item()\n",
    "\n",
    "        # Calculating accuracy:\n",
    "        # test.outputs > 0 returns True or False, by using float() we convert bools to 1.0 and 0.0\n",
    "        # Then, multiply it by two, so for True = 2.0 False = 0.0\n",
    "        # Substract 1 and the labels are either 1.0 or -1.0\n",
    "        predicted = (test_outputs > 0).float() * 2 - 1\n",
    "        correct = (predicted == y_test_tensor).sum().item()\n",
    "        test_accuracy = correct / len(y_test_tensor)\n",
    "\n",
    "    avg_loss = epoch_loss / batches_count\n",
    "    train_loss_history.append(avg_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "    acc_history.append(test_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg loss: {avg_loss:.4f} | Test Acc: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "VKpTxQgZdUGC",
    "outputId": "b71de7d8-bb5d-444f-839c-2e5a6c47bb9c"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_outputs_tensor = model(X_test_tensor)\n",
    "    test_outputs = test_outputs_tensor.numpy()\n",
    "\n",
    "predicted = np.where(test_outputs > 0, 1, -1).flatten()\n",
    "\n",
    "c_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, predicted))\n",
    "c_matrix_display.plot()\n",
    "\n",
    "epochs = range(1, len(train_loss_history) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss_history, label='Train Loss', color='blue')\n",
    "plt.plot(epochs, test_loss_history, label='Test Loss', color='red', linestyle='--')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, acc_history, label='Test Accuracy', color='green')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"F1 SCORE: \", f1_score(y_test, predicted), \" | ACCURACY SCORE: \", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "quantum_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.12 (Qiskit)",
   "language": "python",
   "name": "qiskit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
